{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e9a949",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a395a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2517164184.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install rapidfuzz\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "pip install rapidfuzz\n",
    "from rapidfuzz import process, fuzz\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f6b5df",
   "metadata": {},
   "source": [
    "## Merge cpus data into main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88cd850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "cpus_data = pd.read_csv('cpus.csv', on_bad_lines='warn')\n",
    "\n",
    "# ------------------ NORMALIZATION ------------------\n",
    "\n",
    "def normalize(s):\n",
    "    if not s or pd.isna(s):\n",
    "        return ''\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r'intel|processor|core|cpu', '', s)\n",
    "    s = s.replace('-', ' ')\n",
    "    s = re.sub(r'[^a-z0-9 ]+', ' ', s)\n",
    "    return re.sub(r'\\s+', ' ', s).strip()\n",
    "\n",
    "# ------------------ TYPO/NEAR-MATCH CORRECTIONS ------------------\n",
    "\n",
    "CPU_CORRECTIONS = {\n",
    "    'i5 1135u': 'i5-1135G7', 'i5 1135': 'i5-1135G7',\n",
    "    'i3 1115g7': 'i3-1115G4', 'i3 1124g': 'i3-1125G4',\n",
    "    'i5 1244u': 'i5-1245U', 'i5 1285p': 'i5-1240P', 'i5 1235p': 'i5-1240P', 'i5 12210u': 'i5-1235U',\n",
    "    'i7 13350u': 'i7-1355U', 'i7 13340u': 'i7-1355U', 'i7 1365p': 'i7-1360P', 'i5 1345p': 'i5-1340P',\n",
    "    'i5 8300u': 'i5-8250U', 'i5 8700': 'i5-8300H', 'i5 8265': 'i5-8265U', 'i5 8600': 'i5-8300H',\n",
    "    'i5 8350 vpro': 'i5-8350U', 'i5 8300 vpro': 'i5-8250U', 'i5 8350de': 'i5-8350U', 'i5 8635u': 'i5-8265U',\n",
    "    'i7 8560u': 'i7-8550U', 'i5 7300': 'i5-7300U', 'i5 7300 vpro': 'i5-7300U', 'i5 7400u': 'i5-7200U',\n",
    "    'i5 7400': 'i5-7300HQ', 'i7 7375u': 'i7-7500U', 'i5 6300': 'i5-6300U', 'i7 6600': 'i7-6600U',\n",
    "    'i7 6600hq': 'i7-6700HQ', 'i7 6850hq': 'i7-6820HQ', 'i7 6550u': 'i7-6500U', 'i3 6006': 'i3-6006U',\n",
    "    'i7 4712': 'i7-4712MQ', 'i5 4570m': 'i5-4200M', 'i3 4050u': 'i3-4030U',\n",
    "    'i3 3220': 'i3-3120M', 'i3 3300': 'i3-3120M', 'i5 2415m': 'i5-2410M', 'i7 9900': 'i7-9750H',\n",
    "    'm3 7e': 'Core m3-7Y30', 'n200': 'Intel N200', 'n4500': 'Intel Celeron N4500',\n",
    "    # New Intel Core naming (Core 5/7/9 without \"i\")\n",
    "    'i5 210h': 'Intel Core 5 210H', 'i5 220h': 'Intel Core 5 220H', 'i5 220u': 'Intel Core 5 220U',\n",
    "    'i7 150u': 'Intel Core 7 150U', 'i7 250h': 'Intel Core 7 250H', 'i7 250u': 'Intel Core 7 250U',\n",
    "    'i5 120u': 'Intel Core 5 220U', 'i5 135u': 'Intel Core 5 220U',  # Approximate matches\n",
    "    # Intel Core Ultra series\n",
    "    'i7 155h': 'Intel Core Ultra 7 155H', 'i7 155u': 'Intel Core Ultra 7 155U',\n",
    "    'i9 185h': 'Intel Core Ultra 9 185H',\n",
    "    'i9 th8hk': 'Intel Core i9-8950HK @ 2.90GHz',  # OCR error\n",
    "    # Old Intel mobile CPUs (1st-2nd gen)\n",
    "    'i3 330m': 'i3-330M', 'i3 350m': 'i3-350M', 'i3 370m': 'i3-370M', 'i3 380m': 'i3-380M', 'i3 370': 'i3-370M',\n",
    "    'i5 430m': 'i5-430M', 'i5 520m': 'i5-520M', 'i5 540m': 'i5-540M', 'i5 m480': 'i5-480M', 'i5 m520': 'i5-520M', 'i5 m540': 'i5-540M',\n",
    "    'i7 620m': 'i7-620M', 'i7 920xm': 'i7-920XM',\n",
    "    'i5 750s': 'i5-750S',\n",
    "    # OCR/typo errors\n",
    "    'i3 3em': 'i3-3110M', 'i5 11em': 'i5-1135G7', 'i3 t4005': 'i3-4005U',\n",
    "    # Intel Y-series\n",
    "    'i3 7y30': 'Core m3-7Y30', 'i5 7y54': 'i5-7Y54', 'i5 7y54u': 'i5-7Y54', 'i7 7y75': 'i7-7Y75',\n",
    "    # Lakefield\n",
    "    'i5 l16g7': 'i5-L16G7',\n",
    "    # Typos in AMD\n",
    "    'ryzen 78840u': 'AMD Ryzen 7 8840U', 'ryzen 7730u': 'AMD Ryzen 7 7730U', 'ryzen 8845': 'AMD Ryzen 7 8845HS',\n",
    "    'ryzen 5 220': 'AMD Ryzen 5 PRO 220', 'ryzen 5 740u': 'AMD Ryzen 5 7540U',\n",
    "    'ryzen 7 735hs': 'AMD Ryzen 7 7735HS',\n",
    "    'ryzen 9 hx 370': 'AMD Ryzen 9 HX 370',\n",
    "    # AMD Surface Edition\n",
    "    'ryzen 7 surface edition': 'AMD Ryzen 7 4800U',  # Microsoft Surface edition is based on 4800U\n",
    "    # AMD PRO typos and missing models - map to closest existing PRO variant\n",
    "    'amd ryzen 5 pro 465u': 'AMD Ryzen 5 PRO 4650U', 'ryzen 5 pro 465u': 'AMD Ryzen 5 PRO 4650U',\n",
    "    'amd ryzen 5 pro 4675u': 'AMD Ryzen 5 PRO 4650U', 'ryzen 5 pro 4675u': 'AMD Ryzen 5 PRO 4650U',\n",
    "    'amd ryzen 5 pro 5670u': 'AMD Ryzen 5 PRO 5675U', 'ryzen 5 pro 5670u': 'AMD Ryzen 5 PRO 5675U',\n",
    "    'amd ryzen 5 pro 6675u': 'AMD Ryzen 5 PRO 6650U', 'ryzen 5 pro 6675u': 'AMD Ryzen 5 PRO 6650U',\n",
    "    'amd ryzen 5 pro 4450u': 'AMD Ryzen 5 PRO 4500U', 'ryzen 5 pro 4450u': 'AMD Ryzen 5 PRO 4500U',\n",
    "    'amd ryzen 5 pro 5500u': 'AMD Ryzen 5 PRO 5650U', 'ryzen 5 pro 5500u': 'AMD Ryzen 5 PRO 5650U',\n",
    "    'amd ryzen 5 pro 5850u': 'AMD Ryzen 5 PRO 5650U', 'ryzen 5 pro 5850u': 'AMD Ryzen 5 PRO 5650U',\n",
    "    'amd ryzen 5 pro 4535u': 'AMD Ryzen 5 PRO 4500U', 'ryzen 5 pro 4535u': 'AMD Ryzen 5 PRO 4500U',\n",
    "    'amd ryzen 5 pro 7530': 'AMD Ryzen 5 PRO 7530U', 'ryzen 5 pro 7530': 'AMD Ryzen 5 PRO 7530U',\n",
    "    'amd ryzen 5 pro 3500': 'AMD Ryzen 5 PRO 3500U', 'ryzen 5 pro 3500': 'AMD Ryzen 5 PRO 3500U',\n",
    "    'amd ryzen 5 pro 4650': 'AMD Ryzen 5 PRO 4650U', 'ryzen 5 pro 4650': 'AMD Ryzen 5 PRO 4650U',\n",
    "    'amd ryzen 5 pro 3700u': 'AMD Ryzen 5 PRO 3500U', 'ryzen 5 pro 3700u': 'AMD Ryzen 5 PRO 3500U',\n",
    "    'amd ryzen 7 pro 675ou': 'AMD Ryzen 7 PRO 6850U', 'ryzen 7 pro 675ou': 'AMD Ryzen 7 PRO 6850U',\n",
    "    'amd ryzen 7 pro 7735': 'AMD Ryzen 7 Pro 7735U', 'ryzen 7 pro 7735': 'AMD Ryzen 7 Pro 7735U',\n",
    "    'amd ryzen 7 pro 8865hs': 'AMD Ryzen 7 PRO 8845HS', 'ryzen 7 pro 8865hs': 'AMD Ryzen 7 PRO 8845HS',\n",
    "    'amd ryzen 7 pro 6650u': 'AMD Ryzen 7 PRO 6850U', 'ryzen 7 pro 6650u': 'AMD Ryzen 7 PRO 6850U',\n",
    "    # AMD Ryzen 3 PRO\n",
    "    'amd ryzen 3 pro 2300': 'AMD Ryzen 3 PRO 2300U', 'ryzen 3 pro 2300': 'AMD Ryzen 3 PRO 2300U',\n",
    "    'amd ryzen 3 pro 3300': 'AMD Ryzen 3 PRO 3300U', 'ryzen 3 pro 3300': 'AMD Ryzen 3 PRO 3300U',\n",
    "    'amd ryzen 3 pro 3400g': 'AMD Ryzen 3 PRO 3300U', 'ryzen 3 pro 3400g': 'AMD Ryzen 3 PRO 3300U',\n",
    "    'amd ryzen 3 pro 3500': 'AMD Ryzen 3 PRO 3300U', 'ryzen 3 pro 3500': 'AMD Ryzen 3 PRO 3300U',\n",
    "    'amd ryzen 3 pro s 5450': 'AMD Ryzen 3 PRO 5450U', 'ryzen 3 pro s 5450': 'AMD Ryzen 3 PRO 5450U',\n",
    "}\n",
    "\n",
    "def apply_cpu_corrections(normalized_cpu):\n",
    "    if normalized_cpu in CPU_CORRECTIONS:\n",
    "        return CPU_CORRECTIONS[normalized_cpu]\n",
    "    no_gen = re.sub(r'^\\d+(?:th|nd|rd|st)?\\s*gen\\s*', '', normalized_cpu)\n",
    "    if no_gen in CPU_CORRECTIONS:\n",
    "        return CPU_CORRECTIONS[no_gen]\n",
    "    return None\n",
    "\n",
    "# ------------------ COMMON CPUS BY GENERATION (from cpus.csv) ------------------\n",
    "\n",
    "# Most common laptop CPUs per generation - these must exist in cpus.csv\n",
    "# 'default' is used when no generation is specified (e.g., just \"Intel Core i5\")\n",
    "COMMON_CPUS = {\n",
    "    'intel': {\n",
    "        'i3': {\n",
    "            '14': 'Intel Core i3-1315U',  # 14th gen i3 uses 13th gen naming\n",
    "            '13': 'Intel Core i3-1315U',\n",
    "            '12': 'Intel Core i3-1215U',\n",
    "            '11': 'Intel Core i3-1115G4 @ 3.00GHz',\n",
    "            '10': 'Intel Core i3-1005G1 @ 1.20GHz',\n",
    "            '9': 'Intel Core i3-9100 @ 3.60GHz',\n",
    "            '8': 'Intel Core i3-8130U @ 2.20GHz',\n",
    "            '7': 'Intel Core i3-7100U @ 2.40GHz',\n",
    "            '6': 'Intel Core i3-6100U @ 2.30GHz',\n",
    "            '5': 'Intel Core i3-5005U @ 2.00GHz',\n",
    "            '4': 'Intel Core i3-4005U @ 1.70GHz',\n",
    "            '3': 'Intel Core i3-3120M @ 2.50GHz',\n",
    "            '2': 'Intel Core i3-2350M @ 2.30GHz',\n",
    "            '1': 'Intel Core i3-380M @ 2.53GHz',\n",
    "        },\n",
    "        'i5': {\n",
    "            '14': 'Intel Core Ultra 5 125U',  # 14th gen uses Core Ultra branding\n",
    "            '13': 'Intel Core i5-1335U',\n",
    "            '12': 'Intel Core i5-1235U',\n",
    "            '11': 'Intel Core i5-1135G7 @ 2.40GHz',\n",
    "            '10': 'Intel Core i5-10210U @ 1.60GHz',\n",
    "            '9': 'Intel Core i5-9300H @ 2.40GHz',\n",
    "            '8': 'Intel Core i5-8250U @ 1.60GHz',\n",
    "            '7': 'Intel Core i5-7200U @ 2.50GHz',\n",
    "            '6': 'Intel Core i5-6200U @ 2.30GHz',\n",
    "            '5': 'Intel Core i5-5200U @ 2.20GHz',\n",
    "            '4': 'Intel Core i5-4200U @ 1.60GHz',\n",
    "            '3': 'Intel Core i5-3210M @ 2.50GHz',\n",
    "            '2': 'Intel Core i5-2520M @ 2.50GHz',\n",
    "            '1': 'Intel Core i5-520M @ 2.40GHz',\n",
    "        },\n",
    "        'i7': {\n",
    "            '14': 'Intel Core Ultra 7 155H',  # 14th gen uses Core Ultra branding\n",
    "            '13': 'Intel Core i7-1355U',\n",
    "            '12': 'Intel Core i7-1255U',\n",
    "            '11': 'Intel Core i7-1165G7 @ 2.80GHz',\n",
    "            '10': 'Intel Core i7-10510U @ 1.80GHz',\n",
    "            '9': 'Intel Core i7-9750H @ 2.60GHz',\n",
    "            '8': 'Intel Core i7-8550U @ 1.80GHz',\n",
    "            '7': 'Intel Core i7-7500U @ 2.70GHz',\n",
    "            '6': 'Intel Core i7-6500U @ 2.50GHz',\n",
    "            '5': 'Intel Core i7-5500U @ 2.40GHz',\n",
    "            '4': 'Intel Core i7-4500U @ 1.80GHz',\n",
    "            '3': 'Intel Core i7-3520M @ 2.90GHz',\n",
    "            '2': 'Intel Core i7-2670QM @ 2.20GHz',\n",
    "            '1': 'Intel Core i7-620M @ 2.66GHz',\n",
    "        },\n",
    "        'i9': {\n",
    "            '14': 'Intel Core Ultra 9 185H',  # 14th gen uses Core Ultra branding\n",
    "            '13': 'Intel Core i9-13900H',\n",
    "            '12': 'Intel Core i9-12900H',\n",
    "            '11': 'Intel Core i9-11900H @ 2.50GHz',\n",
    "            '10': 'Intel Core i9-10885H @ 2.40GHz',\n",
    "            '9': 'Intel Core i9-9980HK @ 2.40GHz',\n",
    "            '8': 'Intel Core i9-8950HK @ 2.90GHz',\n",
    "        },\n",
    "    },\n",
    "    'amd': {\n",
    "        'ryzen 3': {\n",
    "            'default': 'AMD Ryzen 3 5300U',  # 5000 series as default\n",
    "            '8': 'AMD Ryzen 3 8300G',\n",
    "            '7': 'AMD Ryzen 3 7320U',\n",
    "            '6': 'AMD Ryzen 3 6300U',\n",
    "            '5': 'AMD Ryzen 3 5300U',\n",
    "            '4': 'AMD Ryzen 3 4300U',\n",
    "            '3': 'AMD Ryzen 3 3200U',\n",
    "        },\n",
    "        'ryzen 5': {\n",
    "            'default': 'AMD Ryzen 5 5500U',  # 5000 series as default\n",
    "            '8': 'AMD Ryzen 5 8640U',\n",
    "            '7': 'AMD Ryzen 5 7530U',\n",
    "            '6': 'AMD Ryzen 5 6600U',\n",
    "            '5': 'AMD Ryzen 5 5500U',\n",
    "            '4': 'AMD Ryzen 5 4500U',\n",
    "            '3': 'AMD Ryzen 5 3500U',\n",
    "        },\n",
    "        'ryzen 7': {\n",
    "            'default': 'AMD Ryzen 7 5700U',  # 5000 series as default\n",
    "            '8': 'AMD Ryzen 7 8840U',\n",
    "            '7': 'AMD Ryzen 7 7730U',\n",
    "            '6': 'AMD Ryzen 7 6800U',\n",
    "            '5': 'AMD Ryzen 7 5700U',\n",
    "            '4': 'AMD Ryzen 7 4700U',\n",
    "            '3': 'AMD Ryzen 7 3700U',\n",
    "        },\n",
    "        'ryzen 9': {\n",
    "            'default': 'AMD Ryzen 9 5900HX',  # 5000 series as default\n",
    "            '8': 'AMD Ryzen 9 8945HS',\n",
    "            '7': 'AMD Ryzen 9 7940HS',\n",
    "            '6': 'AMD Ryzen 9 6900HX',\n",
    "            '5': 'AMD Ryzen 9 5900HX',\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "def detect_generic_cpu(cpu_name):\n",
    "    \"\"\"Detect generic CPU and return (brand, tier, generation) or None.\"\"\"\n",
    "    if not cpu_name or pd.isna(cpu_name):\n",
    "        return None\n",
    "    s = str(cpu_name).lower().strip()\n",
    "    \n",
    "    # Skip Apple/specific models\n",
    "    if any(x in s for x in ['apple', 'bionic', 'm1', 'm2', 'm3', 'ultra']):\n",
    "        return None\n",
    "    if re.search(r'\\bn[0-9]{3,4}\\b', s):  # Intel N-series\n",
    "        return None\n",
    "    \n",
    "    # Skip CPUs with specific model indicators (GHz, core count, suffixes, etc.)\n",
    "    # These are specific enough to try fuzzy matching first\n",
    "    if re.search(r'\\d+\\.\\d+\\s*ghz', s):  # Has GHz spec\n",
    "        return None\n",
    "    if re.search(r'\\d+\\s*core', s):  # Has core count\n",
    "        return None\n",
    "    if re.search(r'[ymqhs]{1,2}$', s):  # Ends with suffix like M, U, H, HS, HQ, etc.\n",
    "        return None\n",
    "    if 'vpro' in s or 'v pro' in s:  # vPro variant\n",
    "        return None\n",
    "    if 'surface' in s:  # Surface edition\n",
    "        return None\n",
    "    if 'hx' in s:  # HX series\n",
    "        return None\n",
    "    \n",
    "    # Skip AMD PRO CPUs with model numbers - these are specific models\n",
    "    if re.search(r'ryzen\\s*\\d\\s+pro\\s+\\d{3,4}', s):\n",
    "        return None\n",
    "    \n",
    "    # Skip AMD Ryzen with ANY model number (4 digits with optional suffix)\n",
    "    if re.search(r'ryzen\\s*\\d\\s+\\d{4}[a-z]*', s):\n",
    "        return None\n",
    "    # Also catch typos like \"ryzen 78840u\" or \"ryzen 7730u\"\n",
    "    if re.search(r'ryzen\\s*\\d{4,5}[a-z]*', s):\n",
    "        return None\n",
    "    \n",
    "    # Skip Intel with new Core 5/7/9 naming (e.g., \"core i5 210h\" -> should be Core 5 210H)\n",
    "    if re.search(r'i[3579]\\s*\\d{3}[a-z]?$', s):  # 3-digit model like 210H, 150U\n",
    "        return None\n",
    "    \n",
    "    # Intel: \"11th gen intel core i5\", \"intel core i7 12th gen\"\n",
    "    intel_match = re.search(\n",
    "        r'(?:(\\d{1,2})(?:th|nd|rd|st)?\\s*gen)?.*?(i[3579])(?:\\s*(\\d{1,2})(?:th|nd|rd|st)?\\s*gen)?', s)\n",
    "    if intel_match:\n",
    "        gen = intel_match.group(1) or intel_match.group(3)\n",
    "        tier = intel_match.group(2)\n",
    "        # Only generic if no specific model number (4-5 digits)\n",
    "        if not re.search(r'i[3579]\\s*[-]?\\s*\\d{4,5}', s):\n",
    "            return ('intel', tier, gen)\n",
    "    \n",
    "    # AMD Ryzen: \"AMD Ryzen 5\", \"Ryzen 7 5000 series\" - but NOT \"Ryzen 5 PRO 7540U\"\n",
    "    amd_match = re.search(r'ryzen\\s*(\\d)(?:\\s*(\\d{4})(?:\\s*series)?)?', s)\n",
    "    if amd_match:\n",
    "        tier = f\"ryzen {amd_match.group(1)}\"\n",
    "        series = amd_match.group(2)\n",
    "        # Only generic if no specific model (no PRO with model, no bare model number)\n",
    "        if not re.search(r'ryzen\\s*\\d\\s+(?:pro\\s+)?\\d{3,4}[a-z]*', s):\n",
    "            gen = series[0] if series else None  # 5000 series -> gen 5\n",
    "            return ('amd', tier, gen)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_common_cpu_name(brand, tier, generation, cpu_lookup):\n",
    "    \"\"\"Get the most common CPU name for a generic specification.\n",
    "    \n",
    "    Returns None if no generation is specified - we can't guess which CPU to use.\n",
    "    Only maps when we have a specific generation.\n",
    "    \"\"\"\n",
    "    if not generation:\n",
    "        # No generation specified (e.g., just \"Intel Core i5\" or \"AMD Ryzen 5\")\n",
    "        # We can't accurately map this to a specific CPU, so return None -> NA\n",
    "        return None\n",
    "    \n",
    "    tier_map = COMMON_CPUS.get(brand, {}).get(tier, {})\n",
    "    \n",
    "    # Try exact generation\n",
    "    cpu_name = tier_map.get(str(generation))\n",
    "    if cpu_name and cpu_name.lower() in cpu_lookup:\n",
    "        return cpu_name\n",
    "    \n",
    "    # Generation specified but not in our map - return None\n",
    "    return None\n",
    "\n",
    "# ------------------ PREPARE CLEANED CPUS ------------------\n",
    "\n",
    "cpus_data['norm'] = cpus_data['name'].apply(normalize)\n",
    "tdp_col = 'tdp(W)' if 'tdp(W)' in cpus_data.columns else 'tdp'\n",
    "cpus = cpus_data[['name', 'norm', 'cores', 'cpumark', tdp_col]].copy()\n",
    "cpus.columns = ['cpu_name', 'norm', 'cores', 'cpu_mark', 'tdp']\n",
    "cpu_norms = cpus['norm'].tolist()\n",
    "cpu_by_name = {row['cpu_name'].lower(): idx for idx, row in cpus.iterrows()}\n",
    "\n",
    "# Find CPU column in data\n",
    "cpu_col = next((c for c in ['cpu_name', 'CPU', 'cpu', 'Cpu'] if c in data.columns), None)\n",
    "if cpu_col is None:\n",
    "    raise ValueError(\"No CPU column found in data\")\n",
    "data['norm_cpu'] = data[cpu_col].apply(normalize)\n",
    "\n",
    "# ------------------ MATCH & MAP ------------------\n",
    "\n",
    "MATCH_THRESHOLD = 60\n",
    "matched = unmatched = generic_matched = corrected = exact_matched = 0\n",
    "scores = []\n",
    "results = []\n",
    "\n",
    "# Create a lookup for exact matching (original name lowercase -> index)\n",
    "cpu_exact_lookup = {row['cpu_name'].lower(): idx for idx, row in cpus.iterrows()}\n",
    "\n",
    "# Helper to try exact match by converting input to likely CPU name format\n",
    "def try_exact_match(original_cpu, cpu_exact_lookup, cpus, cpus_data):\n",
    "    \"\"\"Try to find an exact match for the CPU name.\"\"\"\n",
    "    if not original_cpu or pd.isna(original_cpu):\n",
    "        return None\n",
    "    \n",
    "    # Normalize input: upper to title case, handle common patterns\n",
    "    s = str(original_cpu).strip()\n",
    "    \n",
    "    # Try direct case-insensitive match\n",
    "    if s.lower() in cpu_exact_lookup:\n",
    "        return cpu_exact_lookup[s.lower()]\n",
    "    \n",
    "    # Try with standard formatting: \"AMD RYZEN 5 PRO 7540U\" -> \"AMD Ryzen 5 PRO 7540U\"\n",
    "    formatted = s.title().replace('Amd', 'AMD').replace('Pro', 'PRO').replace('Hs', 'HS').replace('Hx', 'HX')\n",
    "    if formatted.lower() in cpu_exact_lookup:\n",
    "        return cpu_exact_lookup[formatted.lower()]\n",
    "    \n",
    "    # Try removing spaces around numbers: \"INTEL CORE I7 155H\" -> \"Intel Core Ultra 7 155H\"\n",
    "    # This won't catch the Intel Ultra naming, but corrections handle that\n",
    "    \n",
    "    return None\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    original_cpu = row[cpu_col]\n",
    "    n = row['norm_cpu']\n",
    "    \n",
    "    if not n:\n",
    "        results.append({'mapped_cpu_name': 'NA', 'match_score': 0, 'cores': 'NA', \n",
    "                       'cpu_mark': 'NA', 'tdp': 'NA', 'gpu_name': 'NA', 'match_type': 'empty'})\n",
    "        unmatched += 1\n",
    "        scores.append(0)\n",
    "        continue\n",
    "\n",
    "    # Step 0: Try exact match first (for PRO variants and other specific models)\n",
    "    exact_idx = try_exact_match(original_cpu, cpu_exact_lookup, cpus, cpus_data)\n",
    "    if exact_idx is not None:\n",
    "        cpu = cpus.iloc[exact_idx]\n",
    "        results.append({'mapped_cpu_name': cpu['cpu_name'], 'match_score': 100,\n",
    "                       'cores': cpu['cores'], 'cpu_mark': cpu['cpu_mark'], 'tdp': cpu['tdp'],\n",
    "                       'gpu_name': cpus_data.iloc[exact_idx].get('gpu_name', 'NA'),\n",
    "                       'match_type': 'exact'})\n",
    "        exact_matched += 1\n",
    "        scores.append(100)\n",
    "        continue\n",
    "\n",
    "    # Step 1: Check for known typos/corrections\n",
    "    correction = apply_cpu_corrections(n)\n",
    "    if correction:\n",
    "        correction_norm = normalize(correction)\n",
    "        match = process.extractOne(correction_norm, cpu_norms, scorer=fuzz.token_set_ratio)\n",
    "        if match and match[1] >= 80:\n",
    "            _, score, match_idx = match\n",
    "            cpu = cpus.iloc[match_idx]\n",
    "            results.append({'mapped_cpu_name': cpu['cpu_name'], 'match_score': score,\n",
    "                           'cores': cpu['cores'], 'cpu_mark': cpu['cpu_mark'], 'tdp': cpu['tdp'],\n",
    "                           'gpu_name': cpus_data.iloc[match_idx].get('gpu_name', 'NA'),\n",
    "                           'match_type': f'corrected ({original_cpu} -> {correction})'})\n",
    "            corrected += 1\n",
    "            scores.append(score)\n",
    "            continue\n",
    "\n",
    "    # Step 2: Check if generic CPU -> map to common CPU\n",
    "    generic = detect_generic_cpu(original_cpu)\n",
    "    if generic:\n",
    "        brand, tier, generation = generic\n",
    "        common_cpu = get_common_cpu_name(brand, tier, generation, cpu_by_name)\n",
    "        \n",
    "        if common_cpu:\n",
    "            match_idx = cpu_by_name[common_cpu.lower()]\n",
    "            cpu = cpus.iloc[match_idx]\n",
    "            results.append({'mapped_cpu_name': cpu['cpu_name'], 'match_score': 100,\n",
    "                           'cores': cpu['cores'], 'cpu_mark': cpu['cpu_mark'], 'tdp': cpu['tdp'],\n",
    "                           'gpu_name': cpus_data.iloc[match_idx].get('gpu_name', 'NA'),\n",
    "                           'match_type': f'generic->common ({original_cpu})'})\n",
    "            generic_matched += 1\n",
    "            scores.append(100)\n",
    "            continue\n",
    "        else:\n",
    "            # No generation or CPU not found -> NA\n",
    "            results.append({'mapped_cpu_name': 'NA', 'match_score': 0, 'cores': 'NA',\n",
    "                           'cpu_mark': 'NA', 'tdp': 'NA', 'gpu_name': 'NA', 'match_type': 'generic_no_gen'})\n",
    "            unmatched += 1\n",
    "            scores.append(0)\n",
    "            continue\n",
    "\n",
    "    # Step 3: Standard fuzzy matching\n",
    "    match = process.extractOne(n, cpu_norms, scorer=fuzz.token_set_ratio)\n",
    "    if match:\n",
    "        _, score, match_idx = match\n",
    "        scores.append(score)\n",
    "        if score >= MATCH_THRESHOLD:\n",
    "            cpu = cpus.iloc[match_idx]\n",
    "            results.append({'mapped_cpu_name': cpu['cpu_name'], 'match_score': score,\n",
    "                           'cores': cpu['cores'], 'cpu_mark': cpu['cpu_mark'], 'tdp': cpu['tdp'],\n",
    "                           'gpu_name': cpus_data.iloc[match_idx].get('gpu_name', 'NA'), 'match_type': 'fuzzy'})\n",
    "            matched += 1\n",
    "        else:\n",
    "            print(f'Unmatched CPU (score {score}): \"{original_cpu}\"')\n",
    "            results.append({'mapped_cpu_name': 'NA', 'match_score': score, 'cores': 'NA',\n",
    "                           'cpu_mark': 'NA', 'tdp': 'NA', 'gpu_name': 'NA', 'match_type': 'unmatched'})\n",
    "            unmatched += 1\n",
    "    else:\n",
    "        results.append({'mapped_cpu_name': 'NA', 'match_score': 0, 'cores': 'NA',\n",
    "                       'cpu_mark': 'NA', 'tdp': 'NA', 'gpu_name': 'NA', 'match_type': 'no_match'})\n",
    "        unmatched += 1\n",
    "        scores.append(0)\n",
    "\n",
    "# ------------------ MERGE & SAVE ------------------\n",
    "\n",
    "results_data = pd.DataFrame(results)\n",
    "data_merged = pd.concat([data.reset_index(drop=True), results_data], axis=1)\n",
    "data_merged = data_merged.drop(columns=['norm_cpu'])\n",
    "\n",
    "OUT_FN = 'data_with_cpus.csv'\n",
    "data_merged.to_csv(OUT_FN, index=False)\n",
    "\n",
    "total = len(data)\n",
    "avg_score = sum(scores) / len(scores) if scores else 0\n",
    "print(f'\\nWrote {OUT_FN} ({total} rows). Exact: {exact_matched}, Fuzzy: {matched}, Generic: {generic_matched}, Corrected: {corrected}, Unmatched: {unmatched}, Avg score: {avg_score:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69975307",
   "metadata": {},
   "source": [
    "# Merge gpus data into main data using cpu names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(OUT_FN)\n",
    "\n",
    "# Load cleaned GPUs reference\n",
    "gpus_ref = pd.read_csv('gpus.csv')\n",
    "\n",
    "# Normalization function for GPU names (same as in tools/map_gpus.py)\n",
    "def normalize_gpu(s):\n",
    "    if not s or pd.isna(s):\n",
    "        return ''\n",
    "    s = str(s).lower()\n",
    "    s = re.sub(r'\\b(nvidia|geforce|radeon|radeon pro|intel|graphics|gpu|mobile|laptop|pc|mx|with|max-q|ti|gtx|rtx|series|apple)\\b', '', s)\n",
    "    s = s.replace('-', ' ')\n",
    "    s = re.sub(r'[^a-z0-9 ]+', ' ', s)\n",
    "    return re.sub(r'\\s+', ' ', s).strip()\n",
    "\n",
    "# Build normalized GPU lookup\n",
    "gpu_norms = gpus_ref['gpu_name'].apply(normalize_gpu).tolist()\n",
    "gpu_data = gpus_ref.to_dict('records')\n",
    "\n",
    "# Create a lookup dict by exact gpu_name for faster access\n",
    "gpu_by_name = {g['gpu_name'].lower(): g for g in gpu_data}\n",
    "\n",
    "# Best match function using rapidatauzz\n",
    "def best_gpu_match(query, choices):\n",
    "    if not query:\n",
    "        return None\n",
    "    match = process.extractOne(query, choices, scorer=fuzz.token_set_ratio)\n",
    "    if match:\n",
    "        return match  # (choice, score, idx)\n",
    "    return None\n",
    "\n",
    "# Apple GPU mapping based on CPU type\n",
    "APPLE_GPU_MAP = {\n",
    "    # M1 series - 8-core GPU (closest to 19-core performance tier)\n",
    "    'm1': 'Apple 19-core GPU',\n",
    "    'm1 pro': 'Apple 19-core GPU',\n",
    "    'm1 max': 'Apple 38-core GPU',\n",
    "    'm1 ultra': 'Apple 64-core GPU',\n",
    "    # M2 series\n",
    "    'm2': 'Apple 19-core GPU',\n",
    "    'm2 pro': 'Apple 19-core GPU',\n",
    "    'm2 max': 'Apple 38-core GPU',\n",
    "    'm2 ultra': 'Apple 76-core GPU',\n",
    "    # M3 series\n",
    "    'm3': 'Apple 19-core GPU',\n",
    "    'm3 pro': 'Apple 19-core GPU',\n",
    "    'm3 max': 'Apple 38-core GPU',\n",
    "    # M4 series\n",
    "    'm4': 'Apple 19-core GPU',\n",
    "    'm4 pro': 'Apple 38-core GPU',\n",
    "    'm4 max': 'Apple 38-core GPU',\n",
    "}\n",
    "\n",
    "def get_apple_gpu_for_cpu(cpu_name):\n",
    "    \"\"\"Map Apple Silicon CPU to appropriate GPU benchmark entry.\"\"\"\n",
    "    if not cpu_name or pd.isna(cpu_name):\n",
    "        return None\n",
    "    cpu_lower = str(cpu_name).lower()\n",
    "    \n",
    "    # Check from most specific to least specific\n",
    "    for pattern, gpu_name in sorted(APPLE_GPU_MAP.items(), key=lambda x: -len(x[0])):\n",
    "        if pattern in cpu_lower:\n",
    "            return gpu_name\n",
    "    return None\n",
    "\n",
    "# CPU-based GPU inference for CPUs with no gpu_name assigned\n",
    "def infer_gpu_from_cpu(cpu_name):\n",
    "    \"\"\"Infer GPU from CPU name when no gpu_name was assigned.\"\"\"\n",
    "    if not cpu_name or pd.isna(cpu_name):\n",
    "        return None\n",
    "    cpu_lower = str(cpu_name).lower()\n",
    "    \n",
    "    # Qualcomm Snapdragon - use Adreno GPUs\n",
    "    if 'snapdragon' in cpu_lower:\n",
    "        if '8cx' in cpu_lower or '8c' in cpu_lower:\n",
    "            return 'Adreno 680'  # High-end Snapdragon\n",
    "        elif '7c' in cpu_lower:\n",
    "            return 'Adreno 618'  # Mid-range\n",
    "        else:\n",
    "            return 'Adreno 618'  # Default Snapdragon\n",
    "    \n",
    "    # Intel Core 2 Duo / Core Duo - GMA integrated graphics\n",
    "    if 'core 2 duo' in cpu_lower or 'core duo' in cpu_lower:\n",
    "        return 'Intel GMA 4500MHD'  # Common integrated GPU for this era\n",
    "    \n",
    "    # Intel Celeron (old)\n",
    "    if 'celeron' in cpu_lower and ('t3' in cpu_lower or 't1' in cpu_lower):\n",
    "        return 'Intel GMA 4500MHD'\n",
    "    \n",
    "    # Generic Intel Core without model (like \"INTEL CORE 620\") - old laptop\n",
    "    if 'intel' in cpu_lower and 'core' in cpu_lower:\n",
    "        return 'Intel GMA 4500MHD'  # Assume old integrated graphics\n",
    "    \n",
    "    return None\n",
    "\n",
    "# GPU mapping threshold\n",
    "GPU_MATCH_THRESHOLD = 50\n",
    "\n",
    "# Initialize new columns\n",
    "new_data['gpu_match_score'] = np.nan\n",
    "new_data['gpu_g3d_mark'] = np.nan\n",
    "new_data['gpu_g2d_mark'] = np.nan\n",
    "new_data['gpu_tdp'] = np.nan\n",
    "\n",
    "# Map GPUs\n",
    "dedicated_matched = 0\n",
    "integrated_matched = 0\n",
    "apple_matched = 0\n",
    "inferred_matched = 0\n",
    "gpu_unmatched = 0\n",
    "gpu_scores = []\n",
    "\n",
    "# Find the CPU column\n",
    "cpu_col = None\n",
    "for col in ['CPU', 'cpu', 'cpu_name', 'Cpu']:\n",
    "    if col in new_data.columns:\n",
    "        cpu_col = col\n",
    "        break\n",
    "\n",
    "for idx, row in new_data.iterrows():\n",
    "    dedicated = row.get('DEDICATED_GPU')\n",
    "    cpu_name = row.get(cpu_col) if cpu_col else None\n",
    "    \n",
    "    # Determine which GPU to look up\n",
    "    if pd.isna(dedicated) or str(dedicated).strip() == '':\n",
    "        # No dedicated GPU - look up the integrated GPU from gpu_name column\n",
    "        gpu_to_match = row.get('gpu_name')\n",
    "        is_dedicated = False\n",
    "    else:\n",
    "        # Has dedicated GPU - match the dedicated GPU\n",
    "        gpu_to_match = dedicated\n",
    "        is_dedicated = True\n",
    "    \n",
    "    # If no gpu_name, try to infer from CPU (but skip if CPU mapping failed with generic_no_gen)\n",
    "    match_type = row.get('match_type', '')\n",
    "    if (pd.isna(gpu_to_match) or str(gpu_to_match).strip() == '' or str(gpu_to_match).strip() == 'NA') and not is_dedicated:\n",
    "        # Don't infer GPU for CPUs that couldn't be mapped (generic_no_gen means we don't know what CPU it is)\n",
    "        if match_type != 'generic_no_gen':\n",
    "            inferred_gpu = infer_gpu_from_cpu(cpu_name)\n",
    "            if inferred_gpu:\n",
    "                gpu_to_match = inferred_gpu\n",
    "                new_data.at[idx, 'gpu_name'] = inferred_gpu\n",
    "    \n",
    "    # Skip if still no GPU to match\n",
    "    if pd.isna(gpu_to_match) or str(gpu_to_match).strip() == '' or str(gpu_to_match).strip() == 'NA':\n",
    "        gpu_unmatched += 1\n",
    "        continue\n",
    "    \n",
    "    # Special handling for generic \"Apple GPU\"\n",
    "    if 'apple gpu' in str(gpu_to_match).lower():\n",
    "        apple_gpu = get_apple_gpu_for_cpu(cpu_name)\n",
    "        if apple_gpu and apple_gpu.lower() in gpu_by_name:\n",
    "            g = gpu_by_name[apple_gpu.lower()]\n",
    "            new_data.at[idx, 'gpu_name'] = g['gpu_name']\n",
    "            new_data.at[idx, 'gpu_match_score'] = 100\n",
    "            new_data.at[idx, 'gpu_g3d_mark'] = g.get('g3d_mark', None)\n",
    "            new_data.at[idx, 'gpu_g2d_mark'] = g.get('g2d_mark', None)\n",
    "            new_data.at[idx, 'gpu_tdp'] = g.get('tdp(w)', None)\n",
    "            apple_matched += 1\n",
    "            gpu_scores.append(100)\n",
    "            continue\n",
    "    \n",
    "    # Normalize and match GPU\n",
    "    norm_gpu = normalize_gpu(gpu_to_match)\n",
    "    if not norm_gpu:\n",
    "        gpu_unmatched += 1\n",
    "        continue\n",
    "    \n",
    "    match = best_gpu_match(norm_gpu, gpu_norms)\n",
    "    if match:\n",
    "        choice, score, match_idx = match\n",
    "        gpu_scores.append(score)\n",
    "        if score >= GPU_MATCH_THRESHOLD:\n",
    "            g = gpu_data[match_idx]\n",
    "            # Update gpu_name only if it's a dedicated GPU or was inferred\n",
    "            if is_dedicated:\n",
    "                new_data.at[idx, 'gpu_name'] = g['gpu_name']\n",
    "                dedicated_matched += 1\n",
    "            else:\n",
    "                integrated_matched += 1\n",
    "            # Always fill the benchmark attributes\n",
    "            new_data.at[idx, 'gpu_match_score'] = score\n",
    "            new_data.at[idx, 'gpu_g3d_mark'] = g.get('g3d_mark', None)\n",
    "            new_data.at[idx, 'gpu_g2d_mark'] = g.get('g2d_mark', None)\n",
    "            new_data.at[idx, 'gpu_tdp'] = g.get('tdp(w)', None)\n",
    "        else:\n",
    "            # Low score - keep the inferred/assigned name but mark as unmatched\n",
    "            gpu_unmatched += 1\n",
    "    else:\n",
    "        gpu_unmatched += 1\n",
    "        gpu_scores.append(0)\n",
    "\n",
    "# Report\n",
    "avg_gpu_score = sum(gpu_scores) / len(gpu_scores) if gpu_scores else 0\n",
    "print(f'GPU Mapping: Dedicated: {dedicated_matched}, Integrated: {integrated_matched}, Apple: {apple_matched}, Unmatched: {gpu_unmatched}')\n",
    "print(f'Avg score: {avg_gpu_score:.1f}')\n",
    "print(f'\\nSample gpu_name values after mapping:')\n",
    "print(new_data['gpu_name'].dropna().value_counts().head(15))\n",
    "print(f'\\nGPU benchmark columns filled: {new_data[\"gpu_g3d_mark\"].notna().sum()} rows')\n",
    "\n",
    "# Show remaining unmatched\n",
    "still_unmatched = new_data[new_data['gpu_g3d_mark'].isna()]\n",
    "if len(still_unmatched) > 0:\n",
    "    print(f'\\nRemaining unmatched ({len(still_unmatched)} rows):')\n",
    "    print(still_unmatched[['gpu_name', cpu_col]].head(20) if cpu_col else still_unmatched[['gpu_name']].head(20))\n",
    "\n",
    "# Export\n",
    "new_data.to_csv('data_with_cpus_gpus.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e372b6b",
   "metadata": {},
   "source": [
    "# RAM and Storage Data Cleaning\n",
    "\n",
    "This notebook cleans the RAM_TYPE, RAM_SIZE, SSD_SIZE, and HDD_SIZE columns using CPU-based mappings.\n",
    "\n",
    "## Cleaning Steps:\n",
    "1. **Fix swapped columns**: Detect when RAM values are in SSD column and vice versa\n",
    "2. **Handle dual storage**: Split formats like \"1TB+240GB\" into SSD and HDD\n",
    "3. **Fill RAM_TYPE**: Use CPU → DDR type mappings from `cpu_ddr_map.csv`\n",
    "4. **Fill RAM_SIZE**: Use tier-based heuristics (i9→32GB, i7/i5→16GB, i3→8GB)\n",
    "5. **Fill Storage**: Only if BOTH SSD and HDD are empty, use CPU → storage defaults from `cpu_storage_map.csv`\n",
    "6. **Normalize storage**: Convert TB to GB format (1TB → 1000GB)\n",
    "\n",
    "## Input/Output:\n",
    "- **Input**: `data_with_cpus_gpus.csv` (output from cpus_gpus_handling.ipynb with cleaned CPU names)\n",
    "- **Output**: `data_with_cleaned_ram_storage.csv`\n",
    "- **Reference**: `cpu_ddr_map.csv`, `cpu_storage_map.csv` (use cleaned CPU names from cpus.csv)\n",
    "- **CPU Column**: Uses `mapped_cpu_name` (standardized CPU names like \"Intel Core i5-1135G7 @ 2.40GHz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5347fd8a",
   "metadata": {},
   "source": [
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534bba2",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc07b1",
   "metadata": {},
   "source": [
    "## 2. Load Mapping Files\n",
    "\n",
    "### CPU → DDR Type Mapping\n",
    "Maps CPU names to their compatible DDR type (DDR3, DDR4, DDR5, LPDDR3, LPDDR4, LPDDR4X, LPDDR5, LPDDR5X).\n",
    "\n",
    "### CPU → Storage Mapping\n",
    "Maps CPU names to their default storage configuration (type: SSD/HDD, size: 256GB/512GB/1TB/etc).\n",
    "Only used when BOTH SSD_SIZE and HDD_SIZE are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03eef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ddr_map(filepath):\n",
    "    \"\"\"Load CPU to DDR type mapping from csv.\n",
    "    Expected format: cpu_name,ddr_type\n",
    "    Returns dict: {cpu_name: ddr_type}\n",
    "    \"\"\"\n",
    "    ddr_map = {}\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                cpu = row.get('cpu_name', '').strip()\n",
    "                ddr = row.get('ddr_type', '').strip()\n",
    "                if cpu and ddr:\n",
    "                    ddr_map[cpu] = ddr\n",
    "        print(f\"Loaded {len(ddr_map)} CPU → DDR type mappings from {filepath}\")\n",
    "        # Show sample CPU names from mapping file\n",
    "        sample_cpus = list(ddr_map.keys())[:5]\n",
    "        print(f\"Sample CPU names from mapping file: {sample_cpus}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"WARNING: DDR map file not found: {filepath}\")\n",
    "    return ddr_map\n",
    "\n",
    "def load_storage_map(filepath):\n",
    "    \"\"\"Load CPU to storage mapping from csv.\n",
    "    Expected format: cpu_name,storage_type,storage_size\n",
    "    Returns dict: {cpu_name: {'storage_type': 'SSD'/'HDD', 'storage_size': '512GB'}}\n",
    "    \"\"\"\n",
    "    storage_map = {}\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                cpu = row.get('cpu_name', '').strip()\n",
    "                storage_type = row.get('storage_type', '').strip()\n",
    "                storage_size = row.get('storage_size', '').strip()\n",
    "                if cpu and storage_type and storage_size:\n",
    "                    storage_map[cpu] = {\n",
    "                        'storage_type': storage_type,\n",
    "                        'storage_size': storage_size\n",
    "                    }\n",
    "        print(f\"Loaded {len(storage_map)} CPU → storage mappings from {filepath}\")\n",
    "        # Show sample CPU names from mapping file\n",
    "        sample_cpus = list(storage_map.keys())[:5]\n",
    "        print(f\"Sample CPU names from mapping file: {sample_cpus}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"WARNING: Storage map file not found: {filepath}\")\n",
    "    return storage_map\n",
    "\n",
    "# Load mapping files\n",
    "ddr_map = load_ddr_map('cpu_ddr_map.csv')\n",
    "storage_map = load_storage_map('cpu_storage_map.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e0872",
   "metadata": {},
   "source": [
    "## 3. CPU Name Lookup\n",
    "\n",
    "Direct dictionary lookup using cleaned CPU names. \n",
    "\n",
    "**Important**: \n",
    "- `mapped_cpu_name` column may include frequency (e.g., \"Intel Core i5-1135G7 @ 2.40GHz\")\n",
    "- Mapping files (`cpu_ddr_map.csv`, `cpu_storage_map.csv`) don't have frequencies (e.g., \"Intel Core i5-1135G7\")\n",
    "- The function strips \"@ GHz\" before matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a30c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cpu_in_map(cpu_name, cpu_map):\n",
    "    \"\"\"Find CPU in map using direct lookup.\n",
    "    \n",
    "    The mapped_cpu_name from cpus_gpus_handling includes frequency (e.g., \"@ 2.40GHz\"),\n",
    "    but the mapping files don't have frequencies, so we need to strip them.\n",
    "    \n",
    "    Example:\n",
    "    - Input: \"Intel Core i5-1135G7 @ 2.40GHz\"\n",
    "    - Stripped: \"Intel Core i5-1135G7\"\n",
    "    - Matches: \"Intel Core i5-1135G7\" in cpu_ddr_map.csv\n",
    "    \n",
    "    Returns: matched CPU name from map, or None\n",
    "    \"\"\"\n",
    "    if not cpu_name or not cpu_map:\n",
    "        return None\n",
    "    \n",
    "    # Strip frequency: \"Intel Core i5-1135G7 @ 2.40GHz\" -> \"Intel Core i5-1135G7\"\n",
    "    cpu_name_clean = re.sub(r'\\s*@.*', '', str(cpu_name)).strip()\n",
    "    cpu_lower = cpu_name_clean.lower()\n",
    "    \n",
    "    # Direct case-insensitive lookup\n",
    "    for map_cpu in cpu_map.keys():\n",
    "        if cpu_lower == map_cpu.lower():\n",
    "            return map_cpu\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91ef80",
   "metadata": {},
   "source": [
    "## 4. RAM Size Heuristics\n",
    "\n",
    "When RAM_SIZE is missing, estimate based on:\n",
    "1. **CPU suffix** (U-series, H-series, HX, G7, P-series) - Most accurate\n",
    "2. **CPU tier** (i3/i5/i7/i9, Ryzen 3/5/7/9) - Secondary indicator\n",
    "3. **Generation** - Newer gens tend to have more RAM\n",
    "\n",
    "### Intel Suffix Patterns:\n",
    "- **HX-series** (Extreme performance): 32GB (high-end gaming/workstation)\n",
    "- **H-series** (High performance): 16-32GB (gaming laptops)\n",
    "- **P-series** (Performance): 16GB (creator laptops)\n",
    "- **U-series** (Ultra-low power): 8-16GB (thin & light)\n",
    "- **G7/G4** (Iris graphics): 8-16GB (mainstream)\n",
    "\n",
    "### AMD Patterns:\n",
    "- **HX-series**: 32GB\n",
    "- **HS/H-series**: 16-32GB\n",
    "- **U-series**: 8-16GB\n",
    "\n",
    "### Examples:\n",
    "- Intel Core i7-1135G7 → 16GB (i7 + G7 suffix)\n",
    "- Intel Core i5-1135G7 → 16GB (i5 + G7 suffix, not just 8GB)\n",
    "- Intel Core i7-12700H → 16GB (i7 + H-series)\n",
    "- Intel Core i9-13980HX → 32GB (i9 + HX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27949e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ram_size_for_cpu(cpu_name):\n",
    "    \"\"\"Get typical RAM size for a CPU based on suffix, tier, and generation.\n",
    "    \n",
    "    Priority:\n",
    "    1. CPU suffix (HX, H, P, U, G7, etc.) - Most accurate indicator\n",
    "    2. CPU tier (i3/i5/i7/i9, Ryzen 3/5/7/9)\n",
    "    3. Generation (newer = more RAM)\n",
    "    \n",
    "    Returns: RAM size as string (e.g., '16') or None\n",
    "    \"\"\"\n",
    "    if not cpu_name:\n",
    "        return None\n",
    "    \n",
    "    cpu_lower = cpu_name.lower()\n",
    "    cpu_upper = cpu_name.upper()\n",
    "    \n",
    "    # === PRIORITY 1: Check CPU suffix patterns (most accurate) ===\n",
    "    \n",
    "    # HX-series: Extreme performance (32GB)\n",
    "    if 'hx' in cpu_lower or cpu_upper.endswith('HX'):\n",
    "        return \"32\"\n",
    "    \n",
    "    # H-series: High performance gaming/workstation\n",
    "    # i9-H or Ryzen 9-H → 32GB\n",
    "    # i7-H or Ryzen 7-H → 16GB (but could be 32GB in newer gens)\n",
    "    # i5-H → 16GB\n",
    "    if re.search(r'\\d{4,5}h\\b', cpu_lower) or re.search(r'-\\d{4}h\\b', cpu_lower):\n",
    "        # Check tier for H-series\n",
    "        if 'i9' in cpu_lower or 'ryzen 9' in cpu_lower:\n",
    "            return \"32\"\n",
    "        elif 'i7' in cpu_lower or 'ryzen 7' in cpu_lower:\n",
    "            # 11th gen+ i7-H typically have 16GB, but can go 32GB\n",
    "            return \"16\"\n",
    "        elif 'i5' in cpu_lower or 'ryzen 5' in cpu_lower:\n",
    "            return \"16\"\n",
    "        else:\n",
    "            return \"16\"  # Default H-series\n",
    "    \n",
    "    # HS-series: AMD high performance slim (16GB)\n",
    "    if 'hs' in cpu_lower:\n",
    "        if 'ryzen 9' in cpu_lower:\n",
    "            return \"32\"\n",
    "        else:\n",
    "            return \"16\"\n",
    "    \n",
    "    # P-series: Intel Performance (creator laptops, 16GB)\n",
    "    if re.search(r'\\d{4,5}p\\b', cpu_lower):\n",
    "        return \"16\"\n",
    "    \n",
    "    # U-series: Ultra-low power (thin & light)\n",
    "    # i7-U with G7 → 16GB (like i7-1135G7)\n",
    "    # i5-U with G7 → 16GB (like i5-1135G7)\n",
    "    # i7-U without G7 → 8-16GB (check generation)\n",
    "    # i3-U → 8GB\n",
    "    if re.search(r'\\d{4,5}u\\b', cpu_lower) or 'u @' in cpu_lower:\n",
    "        # Check for G7 suffix (Iris Xe graphics - better performance)\n",
    "        if 'g7' in cpu_lower or 'g4' in cpu_lower:\n",
    "            # G7 models typically come with 16GB even for i5\n",
    "            if 'i7' in cpu_lower or 'i5' in cpu_lower:\n",
    "                return \"16\"\n",
    "            elif 'i3' in cpu_lower:\n",
    "                return \"8\"\n",
    "        # U-series without G7\n",
    "        if 'i7' in cpu_lower or 'ryzen 7' in cpu_lower:\n",
    "            # Check generation: 10th gen+ → 16GB, older → 8GB\n",
    "            gen_match = re.search(r'-(\\d{1,2})\\d{3}', cpu_name)\n",
    "            if gen_match:\n",
    "                gen = int(gen_match.group(1))\n",
    "                if gen >= 10:\n",
    "                    return \"16\"\n",
    "            return \"8\"\n",
    "        elif 'i5' in cpu_lower or 'ryzen 5' in cpu_lower:\n",
    "            return \"8\"\n",
    "        elif 'i3' in cpu_lower or 'ryzen 3' in cpu_lower:\n",
    "            return \"8\"\n",
    "        else:\n",
    "            return \"8\"  # Default U-series\n",
    "    \n",
    "    # G7/G4 suffix: Iris Xe graphics (typically 16GB for i5+)\n",
    "    if 'g7' in cpu_lower or 'g4' in cpu_lower:\n",
    "        if 'i7' in cpu_lower or 'i9' in cpu_lower:\n",
    "            return \"16\"\n",
    "        elif 'i5' in cpu_lower:\n",
    "            return \"16\"  # i5-1135G7 typically has 16GB\n",
    "        elif 'i3' in cpu_lower:\n",
    "            return \"8\"\n",
    "    \n",
    "    # Y-series: Ultra-low power (tablets, 8GB)\n",
    "    if re.search(r'\\d{4,5}y\\b', cpu_lower):\n",
    "        return \"8\"\n",
    "    \n",
    "    # M-series: Mobile (8GB)\n",
    "    if 'core m' in cpu_lower or re.search(r'm\\d-', cpu_lower):\n",
    "        return \"8\"\n",
    "    \n",
    "    # === PRIORITY 2: Check CPU tier (if no suffix detected) ===\n",
    "    \n",
    "    # High-end tiers: 32GB\n",
    "    if any(x in cpu_lower for x in ['i9', 'ryzen 9', 'ultra 9', 'ultra9', \n",
    "                                      'threadripper', 'epyc', 'xeon']):\n",
    "        return \"32\"\n",
    "    \n",
    "    # Mid-high tiers: 16GB\n",
    "    if any(x in cpu_lower for x in ['i7', 'ryzen 7', 'ultra 7', 'ultra7']):\n",
    "        return \"16\"\n",
    "    \n",
    "    # Mid tiers: Check generation\n",
    "    if any(x in cpu_lower for x in ['i5', 'ryzen 5', 'ultra 5', 'ultra5']):\n",
    "        # Modern i5 (10th gen+) typically have 16GB\n",
    "        gen_match = re.search(r'-(\\d{1,2})\\d{3}', cpu_name)\n",
    "        if gen_match:\n",
    "            gen = int(gen_match.group(1))\n",
    "            if gen >= 10:\n",
    "                return \"16\"\n",
    "        return \"8\"\n",
    "    \n",
    "    # Entry-level: 8GB\n",
    "    if any(x in cpu_lower for x in ['i3', 'i1', 'ryzen 3', 'ultra 3', 'ultra3',\n",
    "                                      'celeron', 'pentium', 'athlon', 'atom',\n",
    "                                      'core 2', 'core duo',\n",
    "                                      'a4', 'a6', 'a8', 'a9',\n",
    "                                      'a10', 'a12', 'e1', 'e2', 'fx-', 'n95', 'n97', 'n100', 'n200', 'n300']):\n",
    "        return \"8\"\n",
    "    \n",
    "    # Default for unknown: 8GB\n",
    "    return \"8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4ce5d",
   "metadata": {},
   "source": [
    "## 5. Data Validation Helpers\n",
    "\n",
    "Functions to detect:\n",
    "- **Swapped columns**: RAM values in SSD column or vice versa\n",
    "- **RAM values**: 2/4/6/8/12/16/24/32/48/64/96/128 GB\n",
    "- **Storage values**: 256+ GB, TB units, or dual storage (A+B format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ram_value(val):\n",
    "    \"\"\"Check if value looks like RAM (4/8/16/32/64/96/128 GB - realistic laptop/workstation RAM).\"\"\"\n",
    "    if not val:\n",
    "        return False\n",
    "    val_clean = val.strip().upper().replace('GB', '').replace(' ', '')\n",
    "    # Only these are realistic laptop/workstation RAM sizes (128GB is valid for MacBooks/workstations)\n",
    "    return val_clean in ['2', '4', '6', '8', '12', '16', '24', '32', '48', '64', '96', '128']\n",
    "\n",
    "def is_storage_value(val):\n",
    "    \"\"\"Check if value looks like storage (256+ GB or TB, or has +).\"\"\"\n",
    "    if not val:\n",
    "        return False\n",
    "    val_clean = val.strip().upper()\n",
    "    # Contains + means dual storage\n",
    "    if '+' in val_clean:\n",
    "        return True\n",
    "    # TB is always storage\n",
    "    if 'TB' in val_clean:\n",
    "        return True\n",
    "    # GB values >= 256 are likely storage (128GB could be RAM on high-end machines)\n",
    "    num = val_clean.replace('GB', '').replace(' ', '')\n",
    "    try:\n",
    "        return int(num) >= 256\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def needs_swap(ram_val, ssd_val):\n",
    "    \"\"\"Check if RAM and SSD columns appear to be swapped.\n",
    "    Returns True if:\n",
    "    - RAM has storage-like value (>=128GB or TB) AND SSD has RAM-like value, OR\n",
    "    - RAM has storage-like value AND SSD is empty, OR\n",
    "    - RAM is empty AND SSD has RAM-like value\n",
    "    \"\"\"\n",
    "    ram = (ram_val or '').strip()\n",
    "    ssd = (ssd_val or '').strip()\n",
    "    \n",
    "    ram_looks_like_storage = is_storage_value(ram)\n",
    "    ssd_looks_like_ram = is_ram_value(ssd)\n",
    "    ram_looks_like_ram = is_ram_value(ram)\n",
    "    ssd_looks_like_storage = is_storage_value(ssd)\n",
    "    \n",
    "    # Case 1: RAM empty, SSD has RAM value\n",
    "    if not ram and ssd_looks_like_ram:\n",
    "        return True\n",
    "    \n",
    "    # Case 2: RAM has storage value, SSD has RAM value (definitely swapped)\n",
    "    if ram_looks_like_storage and ssd_looks_like_ram:\n",
    "        return True\n",
    "    \n",
    "    # Case 3: RAM has storage value (128GB+) and SSD also has storage value\n",
    "    # This might be swapped too - check if RAM > typical max (64GB)\n",
    "    if ram_looks_like_storage and not ram_looks_like_ram:\n",
    "        # RAM has a storage-like value, likely swapped\n",
    "        # Only swap if SSD is empty or also looks like storage\n",
    "        if not ssd or ssd_looks_like_storage:\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8e000",
   "metadata": {},
   "source": [
    "## 6. Storage Parsing and Normalization\n",
    "\n",
    "- **Parse dual storage**: \"1TB+240GB\" → SSD=1TB, HDD=240GB\n",
    "- **Normalize to GB**: \"1TB\" → \"1000GB\", \"2TB\" → \"2000GB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dual_storage(val):\n",
    "    \"\"\"Parse 'A+B' format like '1TB+240GB' -> (primary_size, secondary_size).\"\"\"\n",
    "    if not val or '+' not in val:\n",
    "        return val, None\n",
    "    parts = val.split('+')\n",
    "    if len(parts) == 2:\n",
    "        return parts[0].strip(), parts[1].strip()\n",
    "    return val, None\n",
    "\n",
    "def normalize_storage_to_gb(val):\n",
    "    \"\"\"Convert storage values to GB format (e.g., '1TB' -> '1000GB', '2TB' -> '2000GB').\n",
    "    Also handles dual storage like '1TB 512GB' or '512GB 1TB' by taking the first part.\"\"\"\n",
    "    if not val:\n",
    "        return val\n",
    "    val_clean = val.strip()\n",
    "    \n",
    "    # Handle dual storage with space separator (e.g., \"1TB 512GB\" or \"512GB 1TB\")\n",
    "    # Take only the first part\n",
    "    if ' ' in val_clean and ('GB' in val_clean.upper() or 'TB' in val_clean.upper()):\n",
    "        parts = val_clean.split()\n",
    "        # Find the first storage-like part\n",
    "        for part in parts:\n",
    "            if 'GB' in part.upper() or 'TB' in part.upper():\n",
    "                val_clean = part\n",
    "                break\n",
    "    \n",
    "    val_upper = val_clean.upper()\n",
    "    \n",
    "    # Handle TB -> GB conversion\n",
    "    if 'TB' in val_upper:\n",
    "        try:\n",
    "            num = float(val_upper.replace('TB', '').strip())\n",
    "            return f\"{int(num * 1000)}GB\"\n",
    "        except:\n",
    "            return val_clean\n",
    "    \n",
    "    # Already in GB or other format, return as-is but ensure GB suffix\n",
    "    if 'GB' in val_upper:\n",
    "        return val_upper\n",
    "    \n",
    "    # Just a number, assume GB\n",
    "    try:\n",
    "        num = int(val_clean)\n",
    "        return f\"{num}GB\"\n",
    "    except:\n",
    "        return val_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e389b5a3",
   "metadata": {},
   "source": [
    "## 7. Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1591ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loaded {len(data)} rows from data_with_cpus_gpus.csv\")\n",
    "print(f\"\\nColumns: {list(data.columns)}\")\n",
    "print(f\"\\nFirst few CPU names from mapped_cpu_name column:\")\n",
    "print(data['mapped_cpu_name'].head(10))\n",
    "print(f\"\\nSample of data:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb3fe1f",
   "metadata": {},
   "source": [
    "## 8. Data Cleaning Pipeline\n",
    "\n",
    "### Processing Steps:\n",
    "1. **Fix swapped columns** (RAM in SSD column or vice versa)\n",
    "2. **Split dual storage** (\"1TB+240GB\" format)\n",
    "3. **Fill RAM_TYPE** using CPU → DDR mappings\n",
    "4. **Fill RAM_SIZE** using tier-based heuristics\n",
    "5. **Fill Storage** only if BOTH SSD and HDD are empty\n",
    "6. **Normalize storage** values to GB format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7adb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize statistics\n",
    "stats = {\n",
    "    'total_rows': len(data),\n",
    "    'ram_type_filled': 0,\n",
    "    'ram_type_unchanged': 0,\n",
    "    'ram_type_not_found': 0,\n",
    "    'ram_size_filled': 0,\n",
    "    'ram_size_unchanged': 0,\n",
    "    'storage_filled': 0,\n",
    "    'storage_unchanged': 0,\n",
    "    'storage_not_found': 0,\n",
    "    'columns_swapped': 0,\n",
    "    'dual_storage_split': 0,\n",
    "}\n",
    "\n",
    "# Track CPUs not found in maps\n",
    "cpus_not_in_ddr_map = set()\n",
    "cpus_not_in_storage_map = set()\n",
    "\n",
    "# Process each row\n",
    "for idx, row in data.iterrows():\n",
    "    # Use mapped_cpu_name (cleaned CPU name from cpus_gpus_handling.ipynb)\n",
    "    cpu_name = str(row.get('mapped_cpu_name', '')).strip() if pd.notna(row.get('mapped_cpu_name')) else ''\n",
    "    \n",
    "    # Skip if CPU mapping failed (NA means CPU couldn't be matched)\n",
    "    if not cpu_name or cpu_name.upper() == 'NA':\n",
    "        continue\n",
    "    \n",
    "    # === STEP 0: Fix swapped columns (RAM in SSD column or vice versa) ===\n",
    "    current_ram_size = str(row.get('RAM_SIZE', '')).strip() if pd.notna(row.get('RAM_SIZE')) else ''\n",
    "    current_ssd = str(row.get('SSD_SIZE', '')).strip() if pd.notna(row.get('SSD_SIZE')) else ''\n",
    "    \n",
    "    if needs_swap(current_ram_size, current_ssd):\n",
    "        # Swap RAM and SSD values\n",
    "        data.at[idx, 'RAM_SIZE'] = current_ssd if is_ram_value(current_ssd) else ''\n",
    "        data.at[idx, 'SSD_SIZE'] = current_ram_size if is_storage_value(current_ram_size) else ''\n",
    "        stats['columns_swapped'] += 1\n",
    "        current_ram_size = data.at[idx, 'RAM_SIZE']\n",
    "        current_ssd = data.at[idx, 'SSD_SIZE']\n",
    "    \n",
    "    # === STEP 0b: Handle dual storage format (e.g., \"1TB+240GB\") ===\n",
    "    current_ssd = str(data.at[idx, 'SSD_SIZE']).strip() if pd.notna(data.at[idx, 'SSD_SIZE']) else ''\n",
    "    if current_ssd and '+' in current_ssd:\n",
    "        primary, secondary = parse_dual_storage(current_ssd)\n",
    "        data.at[idx, 'SSD_SIZE'] = primary  # Keep primary in SSD\n",
    "        # Optionally store secondary in HDD if HDD is empty\n",
    "        current_hdd = str(row.get('HDD_SIZE', '')).strip() if pd.notna(row.get('HDD_SIZE')) else ''\n",
    "        if not current_hdd or current_hdd.lower() in ['', 'nan', 'none', 'null']:\n",
    "            data.at[idx, 'HDD_SIZE'] = secondary if secondary else ''\n",
    "        stats['dual_storage_split'] += 1\n",
    "    \n",
    "    # === Fill RAM_TYPE if empty ===\n",
    "    current_ram_type = str(row.get('RAM_TYPE', '')).strip() if pd.notna(row.get('RAM_TYPE')) else ''\n",
    "    if not current_ram_type or current_ram_type.lower() in ['', 'nan', 'none', 'null']:\n",
    "        matched_cpu = find_cpu_in_map(cpu_name, ddr_map)\n",
    "        if matched_cpu:\n",
    "            data.at[idx, 'RAM_TYPE'] = ddr_map[matched_cpu]\n",
    "            stats['ram_type_filled'] += 1\n",
    "        else:\n",
    "            stats['ram_type_not_found'] += 1\n",
    "            # Track CPU not found in DDR map\n",
    "            cpu_name_clean = re.sub(r'\\s*@.*', '', cpu_name).strip()\n",
    "            cpus_not_in_ddr_map.add(cpu_name_clean)\n",
    "    else:\n",
    "        stats['ram_type_unchanged'] += 1\n",
    "    \n",
    "    # === Fill RAM_SIZE if empty ===\n",
    "    current_ram_size = str(row.get('RAM_SIZE', '')).strip() if pd.notna(row.get('RAM_SIZE')) else ''\n",
    "    if not current_ram_size or current_ram_size.lower() in ['', 'nan', 'none', 'null']:\n",
    "        ram_size = get_ram_size_for_cpu(cpu_name)\n",
    "        if ram_size:\n",
    "            data.at[idx, 'RAM_SIZE'] = ram_size + \"GB\"\n",
    "            stats['ram_size_filled'] += 1\n",
    "    else:\n",
    "        stats['ram_size_unchanged'] += 1\n",
    "    \n",
    "    # === Fill Storage ONLY if BOTH SSD_SIZE and HDD_SIZE are empty ===\n",
    "    current_ssd = str(data.at[idx, 'SSD_SIZE']).strip() if pd.notna(data.at[idx, 'SSD_SIZE']) else ''\n",
    "    current_hdd = str(row.get('HDD_SIZE', '')).strip() if pd.notna(row.get('HDD_SIZE')) else ''\n",
    "    \n",
    "    ssd_empty = not current_ssd or current_ssd.lower() in ['', 'nan', 'none', 'null', '0']\n",
    "    hdd_empty = not current_hdd or current_hdd.lower() in ['', 'nan', 'none', 'null', '0']\n",
    "    \n",
    "    if ssd_empty and hdd_empty:\n",
    "        matched_cpu = find_cpu_in_map(cpu_name, storage_map)\n",
    "        if matched_cpu:\n",
    "            storage_info = storage_map[matched_cpu]\n",
    "            storage_type = storage_info['storage_type']\n",
    "            storage_size = storage_info['storage_size'].replace('GB', '').replace('TB', '000')\n",
    "            \n",
    "            if storage_type == 'SSD':\n",
    "                data.at[idx, 'SSD_SIZE'] = storage_size\n",
    "                data.at[idx, 'HDD_SIZE'] = ''\n",
    "            else:\n",
    "                data.at[idx, 'HDD_SIZE'] = storage_size\n",
    "                data.at[idx, 'SSD_SIZE'] = ''\n",
    "            \n",
    "            stats['storage_filled'] += 1\n",
    "        else:\n",
    "            stats['storage_not_found'] += 1\n",
    "            # Track CPU not found in storage map\n",
    "            cpu_name_clean = re.sub(r'\\s*@.*', '', cpu_name).strip()\n",
    "            cpus_not_in_storage_map.add(cpu_name_clean)\n",
    "    else:\n",
    "        stats['storage_unchanged'] += 1\n",
    "    \n",
    "    # === STEP: Normalize all storage values to GB format (TB -> GB) ===\n",
    "    if pd.notna(data.at[idx, 'SSD_SIZE']) and str(data.at[idx, 'SSD_SIZE']).strip():\n",
    "        data.at[idx, 'SSD_SIZE'] = normalize_storage_to_gb(str(data.at[idx, 'SSD_SIZE']))\n",
    "    if pd.notna(data.at[idx, 'HDD_SIZE']) and str(data.at[idx, 'HDD_SIZE']).strip():\n",
    "        data.at[idx, 'HDD_SIZE'] = normalize_storage_to_gb(str(data.at[idx, 'HDD_SIZE']))\n",
    "\n",
    "print(\"Data cleaning completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01763126",
   "metadata": {},
   "source": [
    "## 9. Display Cleaning Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CLEANING STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total rows processed: {stats['total_rows']}\")\n",
    "print()\n",
    "print(\"RAM_TYPE:\")\n",
    "print(f\"  - Filled from map:     {stats['ram_type_filled']}\")\n",
    "print(f\"  - Already had value:   {stats['ram_type_unchanged']}\")\n",
    "print(f\"  - CPU not in map:      {stats['ram_type_not_found']}\")\n",
    "print()\n",
    "print(\"RAM_SIZE:\")\n",
    "print(f\"  - Filled from tier:    {stats['ram_size_filled']}\")\n",
    "print(f\"  - Already had value:   {stats['ram_size_unchanged']}\")\n",
    "print()\n",
    "print(\"Data Fixes:\")\n",
    "print(f\"  - Columns swapped:     {stats['columns_swapped']} (RAM was in SSD column)\")\n",
    "print(f\"  - Dual storage split:  {stats['dual_storage_split']} (A+B format separated)\")\n",
    "print()\n",
    "print(\"Storage (SSD/HDD):\")\n",
    "print(f\"  - Filled from map:     {stats['storage_filled']}\")\n",
    "print(f\"  - Already had value:   {stats['storage_unchanged']}\")\n",
    "print(f\"  - CPU not in map:      {stats['storage_not_found']}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf11e7",
   "metadata": {},
   "source": [
    "## 9b. CPUs Not Found in Mapping Files\n",
    "\n",
    "These CPUs exist in the data but are missing from the mapping files. We should add them if they are valid CPU models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aef6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CPUs NOT FOUND IN MAPPING FILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n📋 CPUs not in DDR map ({len(cpus_not_in_ddr_map)} unique):\")\n",
    "print(\"-\" * 60)\n",
    "if cpus_not_in_ddr_map:\n",
    "    # Sort alphabetically for easier review\n",
    "    sorted_cpus_ddr = sorted(cpus_not_in_ddr_map)\n",
    "    for i, cpu in enumerate(sorted_cpus_ddr, 1):\n",
    "        print(f\"{i:3}. {cpu}\")\n",
    "else:\n",
    "    print(\"✓ All CPUs found in DDR map!\")\n",
    "\n",
    "print(f\"\\n📁 CPUs not in Storage map ({len(cpus_not_in_storage_map)} unique):\")\n",
    "print(\"-\" * 60)\n",
    "if cpus_not_in_storage_map:\n",
    "    # Sort alphabetically for easier review\n",
    "    sorted_cpus_storage = sorted(cpus_not_in_storage_map)\n",
    "    for i, cpu in enumerate(sorted_cpus_storage, 1):\n",
    "        print(f\"{i:3}. {cpu}\")\n",
    "else:\n",
    "    print(\"✓ All CPUs found in Storage map!\")\n",
    "\n",
    "# Find CPUs missing from BOTH maps\n",
    "cpus_missing_both = cpus_not_in_ddr_map.intersection(cpus_not_in_storage_map)\n",
    "if cpus_missing_both:\n",
    "    print(f\"\\n⚠️  CPUs missing from BOTH maps ({len(cpus_missing_both)} unique):\")\n",
    "    print(\"-\" * 60)\n",
    "    sorted_cpus_both = sorted(cpus_missing_both)\n",
    "    for i, cpu in enumerate(sorted_cpus_both, 1):\n",
    "        print(f\"{i:3}. {cpu}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009aa2e6",
   "metadata": {},
   "source": [
    "## 9c. Export Missing CPUs to CSV\n",
    "\n",
    "Export the missing CPUs to CSV files so you can review them and add valid entries to the mapping files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616c6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export CPUs not in DDR map\n",
    "if cpus_not_in_ddr_map:\n",
    "    missing_ddr_data = pd.DataFrame({\n",
    "        'cpu_name': sorted(cpus_not_in_ddr_map),\n",
    "        'ddr_type': '',  # To be filled manually\n",
    "        'release_year': '',  # To be filled manually\n",
    "        'notes': ''  # To be filled manually\n",
    "    })\n",
    "    missing_ddr_data.to_csv('missing_cpus_ddr_map.csv', index=False)\n",
    "    print(f\"✓ Exported {len(cpus_not_in_ddr_map)} CPUs to 'missing_cpus_ddr_map.csv'\")\n",
    "else:\n",
    "    print(\"✓ No missing CPUs for DDR map\")\n",
    "\n",
    "# Export CPUs not in Storage map\n",
    "if cpus_not_in_storage_map:\n",
    "    missing_storage_data = pd.DataFrame({\n",
    "        'cpu_name': sorted(cpus_not_in_storage_map),\n",
    "        'storage_type': '',  # To be filled manually (SSD/HDD)\n",
    "        'storage_size': '',  # To be filled manually (256GB/512GB/1TB etc)\n",
    "        'tier': '',  # To be filled manually (budget/mid/high)\n",
    "        'notes': ''  # To be filled manually\n",
    "    })\n",
    "    missing_storage_data.to_csv('missing_cpus_storage_map.csv', index=False)\n",
    "    print(f\"✓ Exported {len(cpus_not_in_storage_map)} CPUs to 'missing_cpus_storage_map.csv'\")\n",
    "else:\n",
    "    print(\"✓ No missing CPUs for Storage map\")\n",
    "\n",
    "print(\"\\nℹ️  Review these files, fill in the appropriate values, and append them to:\")\n",
    "print(\"   - cpu_ddr_map.csv\")\n",
    "print(\"   - cpu_storage_map.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0fd633",
   "metadata": {},
   "source": [
    "## 10. Preview Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of cleaned data\n",
    "print(\"\\nSample of cleaned data (mapped_cpu_name, RAM_TYPE, RAM_SIZE, SSD_SIZE, HDD_SIZE):\")\n",
    "display_cols = ['mapped_cpu_name', 'RAM_TYPE', 'RAM_SIZE', 'SSD_SIZE', 'HDD_SIZE']\n",
    "data[display_cols].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f7f792",
   "metadata": {},
   "source": [
    "## 11. Export Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f8aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "output_file = 'data_with_cleaned_ram_storage.csv'\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ Exported {len(data)} rows to {output_file}\")\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d55c61a",
   "metadata": {},
   "source": [
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f46ed8",
   "metadata": {},
   "source": [
    "# Clean prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cdfb15",
   "metadata": {},
   "source": [
    "# removing false prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec74d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENTIAL_TROLLS = {\n",
    "    123,\n",
    "    1111,\n",
    "    321,\n",
    "    222222,\n",
    "    1234,\n",
    "    12345,\n",
    "    123456,\n",
    "    1234567,\n",
    "    12345678,\n",
    "    8976378,\n",
    "    5649841,\n",
    "    123456789,\n",
    "    1223789,\n",
    "}\n",
    "\n",
    "\n",
    "# Minimum number of repeated digits to flag (e.g. 3 catches 111, 999, 333 …)\n",
    "MIN_REPEAT_LENGTH = 3\n",
    "\n",
    "\n",
    "def is_troll_price(price):\n",
    "    \"\"\"Return True if the price is a troll value.\"\"\"\n",
    "    if pd.isna(price):\n",
    "        return False\n",
    "\n",
    "    p = int(price)\n",
    "    s = str(p)\n",
    "\n",
    "    # 1) Repeated single digit: 111, 999, 4444, 111111, 222222222 …\n",
    "    if len(set(s)) == 1 and len(s) >= MIN_REPEAT_LENGTH:\n",
    "        return True\n",
    "\n",
    "    # 2) Sequential digits: 123, 1234, 12345, 123456, 1234567 …\n",
    "    if p in SEQUENTIAL_TROLLS:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "data[\"is_troll_price\"] = data[\"price_preview\"].apply(is_troll_price)\n",
    "# set estimated_price_dzd to NaN where is_troll_price is True\n",
    "data.loc[data[\"is_troll_price\"], \"estimated_price_dzd\"] = np.nan\n",
    "# remove is_troll_price column\n",
    "data.drop(columns=[\"is_troll_price\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e92811",
   "metadata": {},
   "source": [
    "### Predicting the correct price based on the market value of the compenents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca94597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cpu_prices = pd.read_csv(\"cpu_prices.csv\")\n",
    "data_gpu_prices = pd.read_csv(\"gpu_prices.csv\")\n",
    "\n",
    "cpu_price_map = dict(zip(data_cpu_prices[\"cpu_name\"], data_cpu_prices[\"estimated_price\"]))\n",
    "\n",
    "gpu_price_map = dict(zip(data_gpu_prices[\"gpu_name\"], data_gpu_prices[\"estimated_price\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3659a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ram_price(ram_gb):\n",
    "    if ram_gb <= 4:\n",
    "        return 4000\n",
    "    elif ram_gb <= 8:\n",
    "        return 8000\n",
    "    elif ram_gb <= 16:\n",
    "        return 15000\n",
    "    elif ram_gb <= 32:\n",
    "        return 28000\n",
    "    else:\n",
    "        return 40000\n",
    "\n",
    "\n",
    "def estimate_storage_price(ssd_gb, hdd_gb):\n",
    "    price = 0\n",
    "\n",
    "    # SSD\n",
    "    if ssd_gb > 0:\n",
    "        price += (ssd_gb / 256) * 8000  # 256GB ≈ 8k DZD\n",
    "\n",
    "    # HDD\n",
    "    if hdd_gb > 0:\n",
    "        price += (hdd_gb / 1000) * 6000  # 1TB ≈ 6k DZD\n",
    "\n",
    "    return price\n",
    "\n",
    "\n",
    "BRAND_MULTIPLIER = {\n",
    "    \"ROG\": 1.25,  # ASUS ROG (Premium gaming)\n",
    "    \"ALIENWARE\": 1.25,  # Dell Alienware (Premium gaming)\n",
    "    \"STEALTH\": 1.20,  # MSI Stealth (Premium)\n",
    "    \"RAZER\": 1.30,  # Razer (Ultra premium)\n",
    "    \"MAC\": 1.50,  # MacBook (Apple premium)\n",
    "    \"THINKPAD\": 1.15,  # Lenovo ThinkPad (Business premium)\n",
    "    \"VECTOR\": 1.20,  # MSI Vector (Gaming)\n",
    "    \"ZENBOOK\": 1.15,  # ASUS ZenBook (Premium ultrabook)\n",
    "    \"PRECISION\": 1.20,  # Dell Precision (Workstation)\n",
    "    \"TUF\": 1.05,  # ASUS TUF (Value gaming)\n",
    "    \"KATANA\": 1.05,  # MSI Katana (Value gaming)\n",
    "    \"VIVOBOOK\": 1.00,  # ASUS VivoBook (Standard)\n",
    "    \"IDEAPAD\": 0.95,  # Lenovo IdeaPad (Budget)\n",
    "    \"INSPIRON\": 0.95,  # Dell Inspiron (Budget)\n",
    "    \"PAVILION\": 0.95,  # HP Pavilion (Budget)\n",
    "    \"ASPIRE\": 0.90,  # Acer Aspire (Budget)\n",
    "}\n",
    "\n",
    "RAM_PRICE_PER_GB = {\n",
    "    \"DDR5\": 2000,  # DDR5 (Latest, most expensive)\n",
    "    \"DDR5X\": 2200,  # DDR5X (Premium)\n",
    "    \"LPDDR5X\": 2400,  # LPDDR5X (High-end laptops)\n",
    "    \"LPDDR5\": 2100,  # LPDDR5\n",
    "    \"DDR4\": 1500,  # DDR4 (Common)\n",
    "    \"DDR4X\": 1700,  # DDR4X\n",
    "    \"DDR3\": 1000,  # DDR3 (Older)\n",
    "    \"DDR2\": 800,  # DDR2 (Legacy)\n",
    "    \"DEFAULT\": 1500,  # Default if type unknown\n",
    "}\n",
    "\n",
    "\n",
    "def parse_ram_size(ram_str):\n",
    "    \"\"\"Convert RAM size string to GB (numeric)\"\"\"\n",
    "    if pd.isna(ram_str) or ram_str == \"\":\n",
    "        return 0\n",
    "\n",
    "    ram_str = str(ram_str).upper().strip()\n",
    "\n",
    "    # Extract numeric value\n",
    "    numeric_part = \"\".join(filter(lambda x: x.isdigit() or x == \".\", ram_str))\n",
    "    if not numeric_part:\n",
    "        return 0\n",
    "\n",
    "    value = float(numeric_part)\n",
    "\n",
    "    # Convert to GB\n",
    "    if \"MB\" in ram_str:\n",
    "        return value / 1024\n",
    "    elif \"GB\" in ram_str:\n",
    "        return value\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "def parse_storage_size(size_str):\n",
    "    \"\"\"Convert storage size string to GB (numeric)\"\"\"\n",
    "    if pd.isna(size_str) or size_str == \"\":\n",
    "        return 0\n",
    "\n",
    "    size_str = str(size_str).upper().strip()\n",
    "\n",
    "    # Handle combined storage (e.g., \"1TB + 512GB\")\n",
    "    if \"+\" in size_str:\n",
    "        parts = size_str.split(\"+\")\n",
    "        total = 0\n",
    "        for part in parts:\n",
    "            total += parse_storage_size(part.strip())\n",
    "        return total\n",
    "\n",
    "    # Extract numeric value\n",
    "    numeric_part = \"\".join(filter(lambda x: x.isdigit() or x == \".\", size_str))\n",
    "    if not numeric_part:\n",
    "        return 0\n",
    "\n",
    "    value = float(numeric_part)\n",
    "\n",
    "    # Convert to GB\n",
    "    if \"TB\" in size_str:\n",
    "        return value * 1024\n",
    "    elif \"GB\" in size_str:\n",
    "        return value\n",
    "    elif \"MB\" in size_str:\n",
    "        return value / 1024\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "def brand_multiplier(model_name):\n",
    "    for brand, mult in BRAND_MULTIPLIER.items():\n",
    "        if brand.lower() in str(model_name).lower():\n",
    "            return mult\n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def get_ram_price(ram_size_gb, ram_type):\n",
    "    \"\"\"Calculate RAM price based on size and type\"\"\"\n",
    "    if ram_size_gb == 0 or ram_size_gb > 128:  # Cap at 128GB to avoid errors\n",
    "        ram_size_gb = (\n",
    "            min(ram_size_gb, 128) if ram_size_gb > 0 else 8\n",
    "        )  # Default to 8GB if 0\n",
    "\n",
    "    # Determine RAM type price\n",
    "    if pd.isna(ram_type):\n",
    "        price_per_gb = RAM_PRICE_PER_GB[\"DEFAULT\"]\n",
    "    else:\n",
    "        ram_type = str(ram_type).upper().strip()\n",
    "        price_per_gb = RAM_PRICE_PER_GB.get(ram_type, RAM_PRICE_PER_GB[\"DEFAULT\"])\n",
    "\n",
    "    return ram_size_gb * price_per_gb\n",
    "\n",
    "\n",
    "def estimate_price(row):\n",
    "    # CPU\n",
    "    cpu_price = cpu_price_map.get(row[\"mapped_cpu_name\"], 15000)\n",
    "\n",
    "    # GPU\n",
    "    gpu_price = gpu_price_map.get(row[\"gpu_name\"], 0)\n",
    "\n",
    "    # RAM\n",
    "    ram_price = get_ram_price(parse_ram_size(row[\"RAM_SIZE\"]), row[\"RAM_TYPE\"])\n",
    "\n",
    "    # Storage\n",
    "    storage_price = estimate_storage_price(\n",
    "        parse_storage_size(row[\"SSD_SIZE\"]), parse_storage_size(row[\"HDD_SIZE\"])\n",
    "    )\n",
    "\n",
    "    base_price = cpu_price + gpu_price + ram_price + storage_price\n",
    "\n",
    "    # Brand multiplier\n",
    "    final_price = base_price * brand_multiplier(row[\"model_name\"])\n",
    "\n",
    "    return round(final_price, -2)  # round to nearest 100 DZD\n",
    "\n",
    "\n",
    "def fix_price_scale(real_price, estimated_price):\n",
    "    if estimated_price == 0 or real_price == 0:\n",
    "        return real_price\n",
    "\n",
    "    ratio = real_price / estimated_price\n",
    "\n",
    "    while ratio >= 8:\n",
    "        real_price = real_price / 10\n",
    "        ratio = real_price / estimated_price\n",
    "    while ratio <= 1 / 8:\n",
    "        real_price = real_price * 10\n",
    "        ratio = real_price / estimated_price\n",
    "    return real_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"estimated_price_dzd\"] = data.apply(estimate_price, axis=1)\n",
    "\n",
    "data[\"price_corrected\"] = data.apply(\n",
    "    lambda row: fix_price_scale(row[\"price_preview\"], row[\"estimated_price_dzd\"]),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "data[\"price_multiplier_diff\"] = (data[\"price_preview\"] / data[\"estimated_price_dzd\"]).round(2)\n",
    "# remove the estimated_prices \n",
    "data.drop(columns=[\"estimated_price_dzd\"], inplace=True)\n",
    "# remove price_multiplier_diff \n",
    "data.drop(columns=[\"price_multiplier_diff\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79cff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"cleaned_prices.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6714314",
   "metadata": {},
   "source": [
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd495bf4",
   "metadata": {},
   "source": [
    "# Screen-Related Data Cleaning (Final Pipeline Stage)\n",
    "\n",
    "This notebook performs the final cleaning of screen-related features:\n",
    "- SCREEN_SIZE normalization\n",
    "- SCREEN_FREQUENCY cleaning\n",
    "- SCREEN_RESOLUTION parsing and validation\n",
    "- Export final dataset ready for machine learning models\n",
    "\n",
    "## Pipeline Flow:\n",
    "1. `data.csv` → `cpus_gpus_handling.ipynb` → `data_with_cpus_gpus.csv`\n",
    "2. `data_with_cpus_gpus.csv` → `clean_ram_storage.ipynb` → `data_with_cleaned_ram_storage.csv`\n",
    "3. `data_with_cleaned_ram_storage.csv` → **`clean_screen_related.ipynb`** → **`final_cleaned_data.csv`** ✨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d686279",
   "metadata": {},
   "source": [
    "## 1. Load Cleaned Dataset\n",
    "\n",
    "Load the output from the RAM/Storage cleaning pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae32cc",
   "metadata": {},
   "source": [
    "## 2. Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee7f81",
   "metadata": {},
   "source": [
    "Check data types and missing values in screen-related columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82181b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check screen-related columns\n",
    "screen_cols = ['SCREEN_SIZE', 'SCREEN_FREQUENCY', 'SCREEN_RESOLUTION']\n",
    "\n",
    "print(\"Screen-Related Columns Info:\")\n",
    "print(\"=\" * 60)\n",
    "for col in screen_cols:\n",
    "    if col in data.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  - Data type: {data[col].dtype}\")\n",
    "        print(f\"  - Missing: {data[col].isna().sum()} ({data[col].isna().sum()/len(data)*100:.1f}%)\")\n",
    "        print(f\"  - Unique values: {data[col].nunique()}\")\n",
    "        print(f\"  - Sample values: {data[col].dropna().head(5).tolist()}\")\n",
    "    else:\n",
    "        print(f\"\\n{col}: NOT FOUND in dataset\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b6a162",
   "metadata": {},
   "source": [
    "dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b048bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an overview of the dataframe\n",
    "print(\"Dataset Overview:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(data.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nDataframe shape:\")\n",
    "print(f\"  - Rows: {data.shape[0]}\")\n",
    "print(f\"  - Columns: {data.shape[1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nColumn names:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6863823",
   "metadata": {},
   "source": [
    "Display data types and info for screen-related columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7706fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['SCREEN_SIZE','SCREEN_FREQUENCY','SCREEN_RESOLUTION']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a3018",
   "metadata": {},
   "source": [
    "Value distributions\n",
    "Display value distributions for resolution and frequency columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbc48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SCREEN_RESOLUTION'].value_counts(dropna=False)\n",
    "data['SCREEN_FREQUENCY'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e78cad",
   "metadata": {},
   "source": [
    "# 3. Drop SCREEN_FREQUENCY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d9b31a",
   "metadata": {},
   "source": [
    "Remove the SCREEN_FREQUENCY column as it has limited utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1abf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['SCREEN_FREQUENCY'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c771b718",
   "metadata": {},
   "source": [
    "# 4. Clean SCREEN_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a987b6",
   "metadata": {},
   "source": [
    "Convert and normalize SCREEN_SIZE values (replace commas with decimals and extract numeric values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac77b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SCREEN_SIZE'] = (\n",
    "    data['SCREEN_SIZE']\n",
    "    .astype(str)\n",
    "    .str.replace(',', '.', regex=False)\n",
    "    .str.extract(r'(\\d+\\.?\\d*)')[0]\n",
    "    .astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba019bda",
   "metadata": {},
   "source": [
    "Remove impossible values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77900f0",
   "metadata": {},
   "source": [
    "Replace screen sizes outside the valid range (10-20 inches) with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a8b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\n",
    "    (data['SCREEN_SIZE'] < 10) | (data['SCREEN_SIZE'] > 20),\n",
    "    'SCREEN_SIZE'\n",
    "] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebf841",
   "metadata": {},
   "source": [
    "show some stats about SCREEN_SIZE after normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd36dca",
   "metadata": {},
   "source": [
    "Show value counts and statistics for normalized SCREEN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c29416",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "#data['SCREEN_SIZE'].describe()\n",
    "#data['SCREEN_SIZE'].mode()\n",
    "#data['SCREEN_SIZE'].unique()\n",
    "data['SCREEN_SIZE'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc90b578",
   "metadata": {},
   "source": [
    "Snap the values to the nearest canonical size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c49da4",
   "metadata": {},
   "source": [
    "Define canonical screen sizes and snap values to the nearest standard size if within tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f12af",
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_sizes = np.array([\n",
    "    11.6, 12.5, 13.3, 14.0, 15.0, 15.6, 16.0, 17.3      # we can add 14.1 and 16.1\n",
    "])\n",
    "# these standard sizes ~80% of the data\n",
    "# Adding 14.1 & 16.1 improves coverage by ~1.9% only.\n",
    "\n",
    "def snap_screen_size(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    diff = np.abs(canonical_sizes - x)\n",
    "    min_diff = diff.min()\n",
    "    min_diff = np.round(min_diff, 2)\n",
    "    if min_diff <= 0.3:\n",
    "        return canonical_sizes[diff.argmin()]\n",
    "    return x  # keep rare but valid sizes\n",
    "\n",
    "data['SCREEN_SIZE_SNAPPED'] = data['SCREEN_SIZE'].apply(snap_screen_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de9070e",
   "metadata": {},
   "source": [
    "Analyze the coverage of canonical sizes and percentage of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9237c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['SCREEN_SIZE_SNAPPED'].value_counts())\n",
    "\n",
    "is_canonical = data['SCREEN_SIZE_SNAPPED'].isin(canonical_sizes)\n",
    "canonical_pct = is_canonical.mean() * 100\n",
    "\n",
    "none_pct = data['SCREEN_SIZE_SNAPPED'].isna().mean() * 100\n",
    "\n",
    "print(f\"percentage of canonical sizes: {canonical_pct:.2f}%\")\n",
    "print(f\"percentage of none values: {none_pct:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac70b1a",
   "metadata": {},
   "source": [
    "Check value counts by model name to understand data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['model_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e612c824",
   "metadata": {},
   "source": [
    "Display row counts and percentage of missing values grouped by model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cfb871",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = data.groupby('model_name').agg(\n",
    "    total_rows=('SCREEN_SIZE', 'size'),\n",
    "    nan_rows=('SCREEN_SIZE', lambda s: s.isna().sum())\n",
    ")\n",
    "\n",
    "summary['percentage_nan'] = (summary['nan_rows'] / summary['total_rows']) * 100\n",
    "summary = summary.sort_values(by='total_rows', ascending=False)\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd7d85",
   "metadata": {},
   "source": [
    "Check snapped screen size values for a specific model (LATITUDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4852f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data.loc[data['model_name'] == \"LATITUDE\", 'SCREEN_SIZE_SNAPPED']\n",
    "print(result.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a9eb50",
   "metadata": {},
   "source": [
    "Fill missing SCREEN_SIZE values for LATITUDE using model-specific mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mode for LATITUDE model\n",
    "latitude_mode = data[data['model_name'] == 'LATITUDE']['SCREEN_SIZE_SNAPPED'].mode()\n",
    "\n",
    "if len(latitude_mode) > 0:\n",
    "    latitude_mode_value = latitude_mode[0]\n",
    "    print(f\"LATITUDE mode SCREEN_SIZE_SNAPPED: {latitude_mode_value}\")\n",
    "\n",
    "    # Fill missing SCREEN_SIZE_SNAPPED values for LATITUDE with its mode\n",
    "    data.loc[data['model_name'] == 'LATITUDE', 'SCREEN_SIZE_SNAPPED'] = data.loc[data['model_name'] == 'LATITUDE', 'SCREEN_SIZE_SNAPPED'].fillna(latitude_mode_value)\n",
    "\n",
    "    print(f\"Filled missing values for LATITUDE. Now LATITUDE has {data[data['model_name'] == 'LATITUDE']['SCREEN_SIZE_SNAPPED'].isna().sum()} missing values\")\n",
    "else:\n",
    "    print(\"Warning: LATITUDE model has no non-missing SCREEN_SIZE_SNAPPED values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119b8c1",
   "metadata": {},
   "source": [
    "Check snapped screen size values for a specific model (THINKPAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data.loc[data['model_name'] == \"THINKPAD\", 'SCREEN_SIZE_SNAPPED']\n",
    "print(result.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a40dd",
   "metadata": {},
   "source": [
    "Check snapped screen size values for a specific model (MACBOOK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c0b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data.loc[data['model_name'] == \"MACBOOK\", 'SCREEN_SIZE_SNAPPED']\n",
    "print(result.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13183e6d",
   "metadata": {},
   "source": [
    "List all the cpus of MACBOOK laptops and the counts for each one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db47e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 140)\n",
    "\n",
    "macbook_cpus = data.loc[data['model_name'] == 'MACBOOK', 'CPU']\n",
    "print(macbook_cpus.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c7a307",
   "metadata": {},
   "source": [
    "show the count of resolution for each cpu from macbook cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf9f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the count of resolution for each cpu from macbook cpus\n",
    "macbook_data = data[data['model_name'] == 'MACBOOK']\n",
    "\n",
    "for cpu in macbook_data['CPU'].unique():\n",
    "    print(f\"\\n{cpu}:\")\n",
    "    print(macbook_data[macbook_data['CPU'] == cpu]['SCREEN_SIZE_SNAPPED'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b3b1c1",
   "metadata": {},
   "source": [
    "Fill missing SCREEN_SIZE_SNAPPED values for MACBOOK using cpu name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8a9ef8",
   "metadata": {},
   "source": [
    "The Dynamic \"Mode\" Strategy\n",
    "This script automates the mapping by calculating the most common screen size for every CPU present in the MACBOOK subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8a0874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a mapping table: Most frequent Screen Size for every CPU\n",
    "# We filter for MacBooks and drop rows where screen size is missing to find the 'Mode'\n",
    "macbook_data = data[data['model_name'] == 'MACBOOK'].dropna(subset=['SCREEN_SIZE_SNAPPED'])\n",
    "\n",
    "# This calculates the mode (most common value) for each CPU group\n",
    "cpu_mode_mapping = macbook_data.groupby('CPU')['SCREEN_SIZE_SNAPPED'].agg(\n",
    "    lambda x: x.mode().iloc[0] if not x.mode().empty else None\n",
    ").to_dict()\n",
    "\n",
    "# 2. Fill the missing values using the dynamic map\n",
    "# 'mask' identifies exactly which rows need filling\n",
    "mask = (data['model_name'] == 'MACBOOK') & (data['SCREEN_SIZE_SNAPPED'].isna())\n",
    "\n",
    "# Map the CPU names in those rows to our calculated modes\n",
    "data.loc[mask, 'SCREEN_SIZE_SNAPPED'] = data.loc[mask, 'CPU'].map(cpu_mode_mapping)\n",
    "\n",
    "print(f\"Filled missing values for {mask.sum()} MacBook records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743d32c0",
   "metadata": {},
   "source": [
    "Refined Script with Keyword Fallback\n",
    "This version handles the 130+ variations by falling back to general categories if the specific string doesn't have a known screen size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a74478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fallback_size(cpu_string):\n",
    "    \"\"\"Assigns a screen size based on architectural keywords if exact match fails.\"\"\"\n",
    "    cpu_string = str(cpu_string).upper()\n",
    "    if 'M1 MAX' in cpu_string or 'M2 MAX' in cpu_string or 'M3 MAX' in cpu_string:\n",
    "        return 16.0\n",
    "    elif 'M1 PRO' in cpu_string or 'M2 PRO' in cpu_string:\n",
    "        return 14.0 # Most common Pro size in newer models\n",
    "    elif 'I9' in cpu_string:\n",
    "        return 16.0\n",
    "    elif 'M1' in cpu_string or 'M2' in cpu_string or 'M3' in cpu_string or 'I5' in cpu_string:\n",
    "        return 13.3\n",
    "    elif 'I7' in cpu_string:\n",
    "        return 15.0\n",
    "    return np.nan\n",
    "\n",
    "# Apply the specific mapping first\n",
    "data.loc[mask, 'SCREEN_SIZE_SNAPPED'] = data.loc[mask, 'CPU'].map(cpu_mode_mapping)\n",
    "\n",
    "# Apply the fallback for any remaining NaNs in MacBooks\n",
    "final_mask = (data['model_name'] == 'MACBOOK') & (data['SCREEN_SIZE_SNAPPED'].isna())\n",
    "data.loc[final_mask, 'SCREEN_SIZE_SNAPPED'] = data.loc[final_mask, 'CPU'].apply(get_fallback_size)\n",
    "\n",
    "print(\n",
    "    f\"Filled missing values for MACBOOK. \"\n",
    "    f\"Now MACBOOK has \"\n",
    "    f\"{data[data['model_name'] == 'MACBOOK']['SCREEN_SIZE_SNAPPED'].isna().sum()} \"\n",
    "    f\"missing values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a9572",
   "metadata": {},
   "source": [
    "Fill missing SCREEN_SIZE_SNAPPED values for all remaining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6988a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of remaining model names to process\n",
    "remaining_models = [\n",
    "    'THINKPAD', 'ELITEBOOK', 'PAVILION', 'VIVOBOOK', 'PROBOOK', 'INSPIRON', \n",
    "    'SURFACE', 'IDEAPAD', 'ASPIRE', 'XPS', 'STEALTH', \n",
    "    'PRECISION', 'VICTUS', 'TUF', 'VOSTRO', 'ROG', 'ZBOOK', 'LEGION', 'OMEN', \n",
    "    'ZENBOOK', 'NITRO', 'GALAXY', 'YOGA', 'THINKBOOK', 'ENVY', 'DYNABOOK', \n",
    "    'PREDATOR', 'KATANA', 'MAC', 'SWIFT', 'SPECTRE', 'ALIENWARE', 'AERO', \n",
    "    'IMAC', 'BLADE', 'VECTOR', 'TRAVELMATE', 'SPIN', 'STRIX', 'COMPAQ', \n",
    "    'GF', 'OPTIPLEX', 'SWORD', 'TRANSFORMER'\n",
    "]\n",
    "\n",
    "# Process each model\n",
    "for model in remaining_models:\n",
    "    # Calculate the mode for this model\n",
    "    model_mode = data[data['model_name'] == model]['SCREEN_SIZE_SNAPPED'].mode()\n",
    "    \n",
    "    if len(model_mode) > 0:\n",
    "        model_mode_value = model_mode[0]\n",
    "        \n",
    "        # Count missing values before filling\n",
    "        missing_before = data[data['model_name'] == model]['SCREEN_SIZE_SNAPPED'].isna().sum()\n",
    "        \n",
    "        # Fill missing SCREEN_SIZE_SNAPPED values for this model with its mode\n",
    "        data.loc[data['model_name'] == model, 'SCREEN_SIZE_SNAPPED'] = (\n",
    "            data.loc[data['model_name'] == model, 'SCREEN_SIZE_SNAPPED']\n",
    "            .fillna(model_mode_value)\n",
    "        )\n",
    "        \n",
    "        # Count missing values after filling\n",
    "        missing_after = data[data['model_name'] == model]['SCREEN_SIZE_SNAPPED'].isna().sum()\n",
    "        \n",
    "        if missing_before > 0:\n",
    "            print(f\"{model}: Filled {missing_before} missing values with mode {model_mode_value}. Remaining missing: {missing_after}\")\n",
    "    else:\n",
    "        print(f\"Warning: {model} has no non-missing SCREEN_SIZE_SNAPPED values\")\n",
    "\n",
    "print(\"\\nAll remaining models processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc71df9",
   "metadata": {},
   "source": [
    "# 5. Clean SCREEN_RESOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb61771",
   "metadata": {},
   "source": [
    "Normalize text.\n",
    "* Normalize SCREEN_RESOLUTION text (convert to lowercase and remove spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8246fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SCREEN_RESOLUTION'] = (\n",
    "    data['SCREEN_RESOLUTION']\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(' ', '')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c60f36e",
   "metadata": {},
   "source": [
    "Display the frequency distribution of values in the SCREEN_RESOLUTION column after normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904632f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 120)\n",
    "data['SCREEN_RESOLUTION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d42aad",
   "metadata": {},
   "source": [
    "Map resolution values to standard categories (HD, FHD, QHD, 4K, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd733b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize SCREEN_RESOLUTION into standardized resolution tiers\n",
    "resolution_map = {\n",
    "    # HD\n",
    "    '1366x768': 'HD',\n",
    "    '1280x720': 'HD',\n",
    "    'hd': 'HD',\n",
    "\n",
    "    # HD+\n",
    "    '1440x900': 'HD+',\n",
    "    '1600x900': 'HD+',\n",
    "    '1536x1024': 'HD+',\n",
    "    '1280x800': 'HD+',\n",
    "\n",
    "    # FHD\n",
    "    '1920x1080': 'FHD',\n",
    "    '1920x1080fhd': 'FHD',\n",
    "    'fullhd': 'FHD',\n",
    "    'fhd': 'FHD',\n",
    "    '1080p': 'FHD',\n",
    "    'fhd1080p': 'FHD',\n",
    "    '1920x1080fullhd': 'FHD',\n",
    "\n",
    "    # WUXGA (FHD+ / 16:10)\n",
    "    '1920x1200': 'WUXGA',\n",
    "    '1920x1200fhd': 'WUXGA',\n",
    "    '1920x1200fhd+': 'WUXGA',\n",
    "    '1920x1200wuxga': 'WUXGA',\n",
    "    '1920x1280': 'WUXGA',\n",
    "    'fhd+': 'WUXGA',\n",
    "    'fullhd+': 'WUXGA',\n",
    "    'wuxga': 'WUXGA',\n",
    "\n",
    "    # QHD / 2K\n",
    "    '2560x1440': 'QHD',\n",
    "    '2560x1440qhd': 'QHD',\n",
    "    'qhd': 'QHD',\n",
    "    'wqhd': 'QHD',\n",
    "    '2k': 'QHD',\n",
    "    'qhd2k': 'QHD',\n",
    "    '1440p': 'QHD',\n",
    "    '2048x1080': 'QHD',\n",
    "\n",
    "\n",
    "    # QHD+ (16:10)\n",
    "    '2560x1600': 'QHD+',\n",
    "    '2560x1600qhd+': 'QHD+',\n",
    "    '2400x1600': 'QHD+',\n",
    "    '2240x1400': 'QHD+',\n",
    "    '2560x1664': 'QHD+',\n",
    "    '2256x1504': 'QHD+',\n",
    "    'wqxga': 'QHD+',\n",
    "    'wqxga+': 'QHD+',\n",
    "    'qhd+': 'QHD+',\n",
    "    '2.5k': 'QHD+',\n",
    "    '2496x1664': 'QHD+',\n",
    "    '2360x1640': 'QHD+',\n",
    "    '2304x1536': 'QHD+',\n",
    "\n",
    "    # 3K-class (high-density laptop panels)\n",
    "    '2880x1800': '3K',\n",
    "    '2880x1920': '3K',\n",
    "    '3072x1920': '3K',\n",
    "    '3000x2000': '3K',\n",
    "    '3024x1964': '3K',\n",
    "    '3200x2000': '3K',\n",
    "    '2736x1824': '3K',\n",
    "    '2736x1834': '3K',\n",
    "    '2736x1823': '3K',\n",
    "    '3456x2234': '3K',\n",
    "    '3k': '3K',\n",
    "    '2.8k': '3K',\n",
    "    '2880x1864': '3K',\n",
    "    '3koled': '3K',\n",
    "    '2880x1864': '3K',\n",
    "    '3kretina': '3K',\n",
    "\n",
    "    # 4K / UHD\n",
    "    '3840x2160': '4K',\n",
    "    '3840x2400': '4K',\n",
    "    '3456x2160': '4K',\n",
    "    '3240x2160': '4K',\n",
    "    '4k': '4K',\n",
    "    '4kuhd': '4K',\n",
    "\n",
    "    # 5K\n",
    "    '5120x2880': '5K',\n",
    "    '5k': '5K'\n",
    "}\n",
    "\n",
    "data['SCREEN_RESOLUTION_STD'] = (\n",
    "    data['SCREEN_RESOLUTION']\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .map(resolution_map)\n",
    "    .fillna(data['SCREEN_RESOLUTION'])\n",
    ")\n",
    "\n",
    "\n",
    "# resolution hierarchy (for modeling)\n",
    "# HD < HD+ < FHD < WUXGA < QHD < QHD+ < 3K < 4K < 5K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d6ff0",
   "metadata": {},
   "source": [
    "Display the frequency distribution of the normalized SCREEN_RESOLUTION_STD values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8fce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 120)\n",
    "data['SCREEN_RESOLUTION_STD'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac2971f",
   "metadata": {},
   "source": [
    "set non standard SCREEN_RESOLUTION_STD values to nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff97685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set non standard SCREEN_RESOLUTION_STD to NaN\n",
    "valid_resolutions = [\n",
    "    'HD', 'HD+', 'FHD', 'WUXGA', 'QHD', 'QHD+', '3K', '4K', '5K'\n",
    "]\n",
    "\n",
    "data.loc[  # Use .loc to set values in the DataFrame where condition is met\n",
    "    ~data['SCREEN_RESOLUTION_STD'].isin(valid_resolutions), \n",
    "    'SCREEN_RESOLUTION_STD'  # Column to update\n",
    "] = np.nan \n",
    "\n",
    "# Print the frequency count of each unique value in SCREEN_RESOLUTION_STD after setting invalid ones to NaN\n",
    "print(data['SCREEN_RESOLUTION_STD'].value_counts())  \n",
    "# Calculate and display the percentage of missing (NaN) values in SCREEN_RESOLUTION_STD\n",
    "data['SCREEN_RESOLUTION_STD'].isna().mean() * 100  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbbd47d",
   "metadata": {},
   "source": [
    "Show the percentage of missing SCREEN_RESOLUTION_STD values for each model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a002ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = data.groupby('model_name').agg(\n",
    "    total_rows=('SCREEN_RESOLUTION_STD', 'size'),\n",
    "    nan_rows=('SCREEN_RESOLUTION_STD', lambda s: s.isna().sum())\n",
    ")\n",
    "\n",
    "summary['percentage_nan'] = (summary['nan_rows'] / summary['total_rows']) * 100\n",
    "\n",
    "mode_counts = (\n",
    "    data.dropna(subset=['SCREEN_RESOLUTION_STD'])\n",
    "      .groupby('model_name')['SCREEN_RESOLUTION_STD']\n",
    "      .value_counts()\n",
    "      .rename('mode_count')\n",
    "      .reset_index()\n",
    "      .sort_values(['model_name', 'mode_count'], ascending=[True, False])\n",
    "      .drop_duplicates('model_name')\n",
    "      .set_index('model_name')\n",
    "      [['SCREEN_RESOLUTION_STD', 'mode_count']]\n",
    ")\n",
    "\n",
    "summary = summary.join(mode_counts).rename(columns={'SCREEN_RESOLUTION_STD': 'mode_resolution'})\n",
    "\n",
    "summary = summary.sort_values(by='total_rows', ascending=False)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9dc0b9",
   "metadata": {},
   "source": [
    "Fill missing SCREEN_RESOLUTION values with the specific mode for each model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing SCREEN_RESOLUTION_STD by model_name mode\n",
    "for model in summary.index:\n",
    "    mode_value = summary.loc[model, 'mode_resolution']\n",
    "    if pd.notna(mode_value):\n",
    "        mask = (data['model_name'] == model) & (data['SCREEN_RESOLUTION_STD'].isna())\n",
    "        data.loc[mask, 'SCREEN_RESOLUTION_STD'] = mode_value\n",
    "        filled_count = mask.sum()\n",
    "        if filled_count > 0:\n",
    "            print(f\"Filled {filled_count} missing values for {model} with mode {mode_value}\")       \n",
    "print(\"\\nAll models processed for SCREEN_RESOLUTION_STD!\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f265147",
   "metadata": {},
   "source": [
    "# 6. Encode SCREEN_RESOLUTION (for ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d13967",
   "metadata": {},
   "source": [
    "Create numeric encodings for resolution categories for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea49602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode SCREEN_RESOLUTION_STD into numerical values for modeling using this resolution hierarchy \n",
    "# HD < HD+ < FHD < WUXGA < QHD < QHD+ < 3K < 4K < 5K\n",
    "resolution_encoding = {\n",
    "    'HD': 1,\n",
    "    'HD+': 2,\n",
    "    'FHD': 3,\n",
    "    'WUXGA': 4,\n",
    "    'QHD': 5,\n",
    "    'QHD+': 6,\n",
    "    '3K': 7,\n",
    "    '4K': 8,\n",
    "    '5K': 9\n",
    "}\n",
    "\n",
    "data['SCREEN_RESOLUTION_ENC'] = data['SCREEN_RESOLUTION_STD'].map(resolution_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9694a0ef",
   "metadata": {},
   "source": [
    "# 7. Final Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b0cc3",
   "metadata": {},
   "source": [
    "Verify data types and display sample rows of cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e4129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['SCREEN_SIZE_SNAPPED','SCREEN_RESOLUTION_STD','SCREEN_RESOLUTION_ENC']].info()\n",
    "data[['SCREEN_SIZE_SNAPPED','SCREEN_RESOLUTION_STD']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206d769",
   "metadata": {},
   "source": [
    "## 8. Export Final Cleaned Dataset\n",
    "\n",
    "This is the **final dataset** ready for machine learning models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff815b83",
   "metadata": {},
   "source": [
    "Export the fully cleaned dataset ready for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49285f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export final cleaned dataset\n",
    "output_file = \"final_cleaned_data.csv\"\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"✅ FINAL CLEANED DATASET EXPORTED!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"📁 Output file: {output_file}\")\n",
    "print(f\"📊 Total rows: {len(data)}\")\n",
    "print(f\"📋 Total columns: {len(data.columns)}\")\n",
    "print(\"\\n🎯 This dataset is now ready for machine learning models!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show summary statistics\n",
    "print(\"\\n📈 Dataset Summary:\")\n",
    "print(f\"  - CPU mapped: {(data['mapped_cpu_name'] != 'NA').sum()} rows\")\n",
    "print(f\"  - RAM filled: {data['RAM_SIZE'].notna().sum()} rows\")\n",
    "print(f\"  - Storage filled: {((data['SSD_SIZE'].notna()) | (data['HDD_SIZE'].notna())).sum()} rows\")\n",
    "print(f\"  - Screen size cleaned: {data['SCREEN_SIZE'].notna().sum()} rows\")\n",
    "print(f\"  - GPU data: {data['gpu_name'].notna().sum()} rows\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
